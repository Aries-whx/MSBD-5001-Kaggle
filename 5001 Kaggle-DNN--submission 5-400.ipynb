{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wanghanxuan/anaconda3/lib/python3.6/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_9.4.1) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n",
      "/Users/wanghanxuan/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder,minmax_scale\n",
    "from sklearn import model_selection\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('/Users/wanghanxuan/Desktop/BDT Lecture/5001 Foundation of Data Analytics/Kaggle/train.csv')\n",
    "data_test = pd.read_csv('/Users/wanghanxuan/Desktop/BDT Lecture/5001 Foundation of Data Analytics/Kaggle/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data_train,data_test], axis = 0).drop(['id','random_state'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['penalty'] = LabelEncoder().fit_transform(data['penalty'])\n",
    "data['alpha'] = LabelEncoder().fit_transform(data['alpha'])\n",
    "def fun(x):\n",
    "    if x == -1:\n",
    "        return 8\n",
    "    else:\n",
    "        return x\n",
    "data['n_jobs'] = data['n_jobs'].apply(lambda x: fun(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def penalty(x):\n",
    "    if x == 'none':\n",
    "        x = 0\n",
    "    elif x =='l2':\n",
    "        x = 1\n",
    "    elif x =='l1':\n",
    "        x = 2\n",
    "    elif x =='elasticnet':\n",
    "        x = 3\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['penalty'] = data['penalty'].apply(lambda x: penalty(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 13 columns):\n",
      "alpha                   500 non-null int64\n",
      "flip_y                  500 non-null float64\n",
      "l1_ratio                500 non-null float64\n",
      "max_iter                500 non-null int64\n",
      "n_classes               500 non-null int64\n",
      "n_clusters_per_class    500 non-null int64\n",
      "n_features              500 non-null int64\n",
      "n_informative           500 non-null int64\n",
      "n_jobs                  500 non-null int64\n",
      "n_samples               500 non-null int64\n",
      "penalty                 500 non-null int64\n",
      "scale                   500 non-null float64\n",
      "time                    400 non-null float64\n",
      "dtypes: float64(4), int64(9)\n",
      "memory usage: 50.9 KB\n"
     ]
    }
   ],
   "source": [
    "data.index = range(len(data))\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or any {'0', '1', '2'} #mute warnings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy array to DataSet\n",
    "train_x = data.iloc[0:400,0:12]\n",
    "train_y = data.iloc[0:400,12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = data.iloc[400:500,0:12]\n",
    "test_y = data.iloc[400:500,12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get training data\n",
    "# train_x, test_x, train_y, test_y = train_test_split(data1,label,test_size=0.2,random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data is *not* used when calculating the mean and std\n",
    "train_x = minmax_scale(train_x, feature_range=(0, 1), axis=0, copy=True)\n",
    "test_x = minmax_scale(test_x, feature_range=(0, 1), axis=0, copy=True)\n",
    "# mean = train_x.mean(axis=0)\n",
    "# std = train_x.std(axis=0)\n",
    "# train_x = (train_x - mean) / std\n",
    "# test_x = (test_x - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 256)               3328      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 135,169\n",
      "Trainable params: 135,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    model = keras.Sequential()\n",
    "    model.add(Dense(256, activation='relu', input_dim=12))\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(Dense(256, activation='relu',kernel_regularizer=regularizers.l2(0.01)))\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(Dense(256, activation='relu',kernel_regularizer=regularizers.l2(0.01)))\n",
    "    \n",
    "#   model.add(Dense(128, activation='relu'))\n",
    "    \n",
    "    #model.add(Dense(128, activation='relu'))\n",
    "    #model.add(Dropout(0.5))\n",
    "\n",
    "    \n",
    "    model.add(Dense(1, activation='relu'))\n",
    "\n",
    "\n",
    "    #optimizer = keras.optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n",
    "\n",
    "\n",
    "    model.compile(loss='mse',\n",
    "                    optimizer='adam',\n",
    "                    metrics=['mae'])\n",
    "    \n",
    "    \n",
    "    \n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 360 samples, validate on 40 samples\n",
      "Epoch 1/500\n",
      "360/360 [==============================] - 1s 2ms/step - loss: 26.6000 - mean_absolute_error: 2.6530 - val_loss: 12.6166 - val_mean_absolute_error: 2.3545\n",
      "Epoch 2/500\n",
      "360/360 [==============================] - 0s 328us/step - loss: 17.2284 - mean_absolute_error: 2.1312 - val_loss: 8.2784 - val_mean_absolute_error: 1.9076\n",
      "Epoch 3/500\n",
      "360/360 [==============================] - 0s 341us/step - loss: 13.5763 - mean_absolute_error: 1.7933 - val_loss: 6.5804 - val_mean_absolute_error: 1.6335\n",
      "Epoch 4/500\n",
      "360/360 [==============================] - 0s 373us/step - loss: 10.5359 - mean_absolute_error: 1.5270 - val_loss: 6.0875 - val_mean_absolute_error: 1.6275\n",
      "Epoch 5/500\n",
      "360/360 [==============================] - 0s 363us/step - loss: 8.1882 - mean_absolute_error: 1.3433 - val_loss: 4.1014 - val_mean_absolute_error: 0.9181\n",
      "Epoch 6/500\n",
      "360/360 [==============================] - 0s 357us/step - loss: 8.3135 - mean_absolute_error: 1.3975 - val_loss: 5.0889 - val_mean_absolute_error: 1.1022\n",
      "Epoch 7/500\n",
      "360/360 [==============================] - 0s 347us/step - loss: 7.1263 - mean_absolute_error: 1.3462 - val_loss: 6.6824 - val_mean_absolute_error: 1.5942\n",
      "Epoch 8/500\n",
      "360/360 [==============================] - 0s 354us/step - loss: 5.6504 - mean_absolute_error: 1.1049 - val_loss: 4.7394 - val_mean_absolute_error: 0.9193\n",
      "Epoch 9/500\n",
      "360/360 [==============================] - 0s 348us/step - loss: 5.8980 - mean_absolute_error: 1.0776 - val_loss: 10.9386 - val_mean_absolute_error: 1.7606\n",
      "Epoch 10/500\n",
      "360/360 [==============================] - 0s 336us/step - loss: 5.5519 - mean_absolute_error: 1.1446 - val_loss: 4.1502 - val_mean_absolute_error: 0.9371\n",
      "Epoch 11/500\n",
      "360/360 [==============================] - 0s 395us/step - loss: 4.2804 - mean_absolute_error: 0.9009 - val_loss: 5.1571 - val_mean_absolute_error: 0.8586\n",
      "Epoch 12/500\n",
      "360/360 [==============================] - 0s 535us/step - loss: 4.0469 - mean_absolute_error: 0.9203 - val_loss: 4.6876 - val_mean_absolute_error: 1.0737\n",
      "Epoch 13/500\n",
      "360/360 [==============================] - 0s 514us/step - loss: 4.4976 - mean_absolute_error: 0.9442 - val_loss: 3.9450 - val_mean_absolute_error: 0.9406\n",
      "Epoch 14/500\n",
      "360/360 [==============================] - 0s 480us/step - loss: 3.4329 - mean_absolute_error: 0.8069 - val_loss: 3.5979 - val_mean_absolute_error: 0.7710\n",
      "Epoch 15/500\n",
      "360/360 [==============================] - 0s 455us/step - loss: 3.1051 - mean_absolute_error: 0.7204 - val_loss: 3.8283 - val_mean_absolute_error: 0.8161\n",
      "Epoch 16/500\n",
      "360/360 [==============================] - 0s 465us/step - loss: 3.6584 - mean_absolute_error: 0.8512 - val_loss: 3.4491 - val_mean_absolute_error: 0.8471\n",
      "Epoch 17/500\n",
      "360/360 [==============================] - 0s 540us/step - loss: 2.7443 - mean_absolute_error: 0.6485 - val_loss: 3.5185 - val_mean_absolute_error: 0.8513\n",
      "Epoch 18/500\n",
      "360/360 [==============================] - 0s 477us/step - loss: 2.9996 - mean_absolute_error: 0.7158 - val_loss: 3.5932 - val_mean_absolute_error: 0.8167\n",
      "Epoch 19/500\n",
      "360/360 [==============================] - 0s 420us/step - loss: 3.1799 - mean_absolute_error: 0.7415 - val_loss: 3.6639 - val_mean_absolute_error: 0.8226\n",
      "Epoch 20/500\n",
      "360/360 [==============================] - 0s 526us/step - loss: 3.2258 - mean_absolute_error: 0.7844 - val_loss: 4.1485 - val_mean_absolute_error: 0.9116\n",
      "Epoch 21/500\n",
      "360/360 [==============================] - 0s 434us/step - loss: 2.9684 - mean_absolute_error: 0.7390 - val_loss: 3.1885 - val_mean_absolute_error: 0.7914\n",
      "Epoch 22/500\n",
      "360/360 [==============================] - 0s 473us/step - loss: 3.1933 - mean_absolute_error: 0.7464 - val_loss: 4.0917 - val_mean_absolute_error: 0.8892\n",
      "Epoch 23/500\n",
      "360/360 [==============================] - 0s 458us/step - loss: 2.5317 - mean_absolute_error: 0.6411 - val_loss: 3.7934 - val_mean_absolute_error: 0.8539\n",
      "Epoch 24/500\n",
      "360/360 [==============================] - 0s 398us/step - loss: 3.6455 - mean_absolute_error: 0.8023 - val_loss: 3.1462 - val_mean_absolute_error: 0.7424\n",
      "Epoch 25/500\n",
      "360/360 [==============================] - 0s 343us/step - loss: 2.5679 - mean_absolute_error: 0.6126 - val_loss: 2.8991 - val_mean_absolute_error: 0.7301\n",
      "Epoch 26/500\n",
      "360/360 [==============================] - 0s 349us/step - loss: 3.2852 - mean_absolute_error: 0.7542 - val_loss: 3.2769 - val_mean_absolute_error: 0.8777\n",
      "Epoch 27/500\n",
      "360/360 [==============================] - 0s 358us/step - loss: 4.1013 - mean_absolute_error: 0.9514 - val_loss: 3.4135 - val_mean_absolute_error: 0.8100\n",
      "Epoch 28/500\n",
      "360/360 [==============================] - 0s 521us/step - loss: 2.6022 - mean_absolute_error: 0.6938 - val_loss: 3.5217 - val_mean_absolute_error: 0.8593\n",
      "Epoch 29/500\n",
      "360/360 [==============================] - 0s 500us/step - loss: 2.3604 - mean_absolute_error: 0.6344 - val_loss: 2.8763 - val_mean_absolute_error: 0.8969\n",
      "Epoch 30/500\n",
      "360/360 [==============================] - 0s 423us/step - loss: 2.2780 - mean_absolute_error: 0.6317 - val_loss: 2.8967 - val_mean_absolute_error: 0.7721\n",
      "Epoch 31/500\n",
      "360/360 [==============================] - 0s 464us/step - loss: 2.3773 - mean_absolute_error: 0.6488 - val_loss: 4.1751 - val_mean_absolute_error: 0.9187\n",
      "Epoch 32/500\n",
      "360/360 [==============================] - 0s 384us/step - loss: 2.3920 - mean_absolute_error: 0.6413 - val_loss: 2.8510 - val_mean_absolute_error: 0.7978\n",
      "Epoch 33/500\n",
      "360/360 [==============================] - 0s 352us/step - loss: 2.8030 - mean_absolute_error: 0.7386 - val_loss: 3.0229 - val_mean_absolute_error: 0.8535\n",
      "Epoch 34/500\n",
      "360/360 [==============================] - 0s 349us/step - loss: 2.0769 - mean_absolute_error: 0.6291 - val_loss: 4.5542 - val_mean_absolute_error: 1.1945\n",
      "Epoch 35/500\n",
      "360/360 [==============================] - 0s 400us/step - loss: 2.8170 - mean_absolute_error: 0.7717 - val_loss: 3.0311 - val_mean_absolute_error: 0.7692\n",
      "Epoch 36/500\n",
      "360/360 [==============================] - 0s 563us/step - loss: 2.4076 - mean_absolute_error: 0.6410 - val_loss: 4.2000 - val_mean_absolute_error: 1.0278\n",
      "Epoch 37/500\n",
      "360/360 [==============================] - 0s 451us/step - loss: 2.4616 - mean_absolute_error: 0.7063 - val_loss: 2.7734 - val_mean_absolute_error: 0.8226\n",
      "Epoch 38/500\n",
      "360/360 [==============================] - 0s 473us/step - loss: 1.8233 - mean_absolute_error: 0.5773 - val_loss: 2.8609 - val_mean_absolute_error: 0.7954\n",
      "Epoch 39/500\n",
      "360/360 [==============================] - 0s 391us/step - loss: 1.7610 - mean_absolute_error: 0.5419 - val_loss: 4.7034 - val_mean_absolute_error: 1.0220\n",
      "Epoch 40/500\n",
      "360/360 [==============================] - 0s 490us/step - loss: 2.0309 - mean_absolute_error: 0.5969 - val_loss: 3.5583 - val_mean_absolute_error: 0.9276\n",
      "Epoch 41/500\n",
      "360/360 [==============================] - 0s 465us/step - loss: 2.3368 - mean_absolute_error: 0.7039 - val_loss: 3.2529 - val_mean_absolute_error: 0.9052\n",
      "Epoch 42/500\n",
      "360/360 [==============================] - 0s 444us/step - loss: 1.8229 - mean_absolute_error: 0.5755 - val_loss: 3.9395 - val_mean_absolute_error: 0.9519\n",
      "Epoch 43/500\n",
      "360/360 [==============================] - 0s 539us/step - loss: 2.1366 - mean_absolute_error: 0.6498 - val_loss: 2.6406 - val_mean_absolute_error: 0.6921\n",
      "Epoch 44/500\n",
      "360/360 [==============================] - 0s 451us/step - loss: 1.5415 - mean_absolute_error: 0.4750 - val_loss: 2.8808 - val_mean_absolute_error: 0.8031\n",
      "Epoch 45/500\n",
      "360/360 [==============================] - 0s 530us/step - loss: 1.5789 - mean_absolute_error: 0.5211 - val_loss: 3.0508 - val_mean_absolute_error: 0.7955\n",
      "Epoch 46/500\n",
      "360/360 [==============================] - 0s 361us/step - loss: 1.6560 - mean_absolute_error: 0.5353 - val_loss: 3.2585 - val_mean_absolute_error: 0.9069\n",
      "Epoch 47/500\n",
      "360/360 [==============================] - 0s 320us/step - loss: 2.2855 - mean_absolute_error: 0.6796 - val_loss: 2.9385 - val_mean_absolute_error: 0.8739\n",
      "Epoch 48/500\n",
      "360/360 [==============================] - 0s 326us/step - loss: 2.0211 - mean_absolute_error: 0.6340 - val_loss: 2.6848 - val_mean_absolute_error: 0.7867\n",
      "Epoch 49/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360/360 [==============================] - 0s 567us/step - loss: 2.3444 - mean_absolute_error: 0.7636 - val_loss: 2.8159 - val_mean_absolute_error: 0.9029\n",
      "Epoch 50/500\n",
      "360/360 [==============================] - 0s 405us/step - loss: 2.9050 - mean_absolute_error: 0.8551 - val_loss: 3.9442 - val_mean_absolute_error: 1.3228\n",
      "Epoch 51/500\n",
      "360/360 [==============================] - 0s 539us/step - loss: 3.0351 - mean_absolute_error: 0.8146 - val_loss: 2.3606 - val_mean_absolute_error: 0.7477\n",
      "Epoch 52/500\n",
      "360/360 [==============================] - 0s 582us/step - loss: 2.5642 - mean_absolute_error: 0.7322 - val_loss: 2.5828 - val_mean_absolute_error: 0.7132\n",
      "Epoch 53/500\n",
      "360/360 [==============================] - 0s 640us/step - loss: 2.2214 - mean_absolute_error: 0.7135 - val_loss: 3.2733 - val_mean_absolute_error: 0.8489\n",
      "Epoch 54/500\n",
      "360/360 [==============================] - 0s 369us/step - loss: 2.0333 - mean_absolute_error: 0.6907 - val_loss: 2.0192 - val_mean_absolute_error: 0.6178\n",
      "Epoch 55/500\n",
      "360/360 [==============================] - 0s 330us/step - loss: 1.7025 - mean_absolute_error: 0.5451 - val_loss: 3.2195 - val_mean_absolute_error: 0.8775\n",
      "Epoch 56/500\n",
      "360/360 [==============================] - 0s 327us/step - loss: 4.3569 - mean_absolute_error: 1.0394 - val_loss: 3.4515 - val_mean_absolute_error: 0.9342\n",
      "Epoch 57/500\n",
      "360/360 [==============================] - 0s 323us/step - loss: 1.9358 - mean_absolute_error: 0.6246 - val_loss: 2.2862 - val_mean_absolute_error: 0.7208\n",
      "Epoch 58/500\n",
      "360/360 [==============================] - 0s 340us/step - loss: 1.7321 - mean_absolute_error: 0.5697 - val_loss: 3.4543 - val_mean_absolute_error: 0.9651\n",
      "Epoch 59/500\n",
      "360/360 [==============================] - 0s 342us/step - loss: 1.4237 - mean_absolute_error: 0.5029 - val_loss: 2.2838 - val_mean_absolute_error: 0.7214\n",
      "Epoch 60/500\n",
      "360/360 [==============================] - 0s 342us/step - loss: 1.2447 - mean_absolute_error: 0.4506 - val_loss: 2.4307 - val_mean_absolute_error: 0.7273\n",
      "Epoch 61/500\n",
      "360/360 [==============================] - 0s 383us/step - loss: 1.1925 - mean_absolute_error: 0.4390 - val_loss: 3.2839 - val_mean_absolute_error: 0.9593\n",
      "Epoch 62/500\n",
      "360/360 [==============================] - 0s 372us/step - loss: 1.4212 - mean_absolute_error: 0.5287 - val_loss: 2.1885 - val_mean_absolute_error: 0.6837\n",
      "Epoch 63/500\n",
      "360/360 [==============================] - 0s 341us/step - loss: 1.5263 - mean_absolute_error: 0.5358 - val_loss: 2.0642 - val_mean_absolute_error: 0.6805\n",
      "Epoch 64/500\n",
      "360/360 [==============================] - 0s 362us/step - loss: 1.7383 - mean_absolute_error: 0.5360 - val_loss: 3.5597 - val_mean_absolute_error: 1.0064\n",
      "Epoch 65/500\n",
      "360/360 [==============================] - 0s 359us/step - loss: 1.5980 - mean_absolute_error: 0.5389 - val_loss: 2.2318 - val_mean_absolute_error: 0.7250\n",
      "Epoch 66/500\n",
      "360/360 [==============================] - 0s 327us/step - loss: 1.2019 - mean_absolute_error: 0.4515 - val_loss: 2.0213 - val_mean_absolute_error: 0.6775\n",
      "Epoch 67/500\n",
      "360/360 [==============================] - 0s 336us/step - loss: 1.0566 - mean_absolute_error: 0.3903 - val_loss: 2.0324 - val_mean_absolute_error: 0.6311\n",
      "Epoch 68/500\n",
      "360/360 [==============================] - 0s 345us/step - loss: 1.0510 - mean_absolute_error: 0.4021 - val_loss: 2.0610 - val_mean_absolute_error: 0.7160\n",
      "Epoch 69/500\n",
      "360/360 [==============================] - 0s 345us/step - loss: 1.8331 - mean_absolute_error: 0.6189 - val_loss: 4.9724 - val_mean_absolute_error: 1.0822\n",
      "Epoch 70/500\n",
      "360/360 [==============================] - 0s 353us/step - loss: 2.1691 - mean_absolute_error: 0.7209 - val_loss: 2.2388 - val_mean_absolute_error: 0.7361\n",
      "Epoch 71/500\n",
      "360/360 [==============================] - 0s 341us/step - loss: 1.4524 - mean_absolute_error: 0.5108 - val_loss: 2.1654 - val_mean_absolute_error: 0.7107\n",
      "Epoch 72/500\n",
      "360/360 [==============================] - 0s 401us/step - loss: 2.0382 - mean_absolute_error: 0.6611 - val_loss: 2.4826 - val_mean_absolute_error: 0.7181\n",
      "Epoch 73/500\n",
      "360/360 [==============================] - 0s 396us/step - loss: 2.3431 - mean_absolute_error: 0.7165 - val_loss: 2.2901 - val_mean_absolute_error: 0.6528\n",
      "Epoch 74/500\n",
      "360/360 [==============================] - 0s 349us/step - loss: 2.6858 - mean_absolute_error: 0.6883 - val_loss: 9.9255 - val_mean_absolute_error: 1.4587\n",
      "Epoch 75/500\n",
      "360/360 [==============================] - 0s 357us/step - loss: 2.5896 - mean_absolute_error: 0.7597 - val_loss: 1.8462 - val_mean_absolute_error: 0.6867\n",
      "Epoch 76/500\n",
      "360/360 [==============================] - 0s 330us/step - loss: 2.4441 - mean_absolute_error: 0.7606 - val_loss: 6.3261 - val_mean_absolute_error: 1.0742\n",
      "Epoch 77/500\n",
      "360/360 [==============================] - 0s 469us/step - loss: 1.9203 - mean_absolute_error: 0.5983 - val_loss: 2.6108 - val_mean_absolute_error: 0.8582\n",
      "Epoch 78/500\n",
      "360/360 [==============================] - 0s 627us/step - loss: 1.8720 - mean_absolute_error: 0.6507 - val_loss: 2.1667 - val_mean_absolute_error: 0.7446\n",
      "Epoch 79/500\n",
      "360/360 [==============================] - 0s 472us/step - loss: 1.2981 - mean_absolute_error: 0.4734 - val_loss: 1.7090 - val_mean_absolute_error: 0.5999\n",
      "Epoch 80/500\n",
      "360/360 [==============================] - 0s 473us/step - loss: 1.2666 - mean_absolute_error: 0.4615 - val_loss: 1.8445 - val_mean_absolute_error: 0.6343\n",
      "Epoch 81/500\n",
      "360/360 [==============================] - 0s 407us/step - loss: 1.1185 - mean_absolute_error: 0.4466 - val_loss: 1.9782 - val_mean_absolute_error: 0.6716\n",
      "Epoch 82/500\n",
      "360/360 [==============================] - 0s 406us/step - loss: 0.9816 - mean_absolute_error: 0.3940 - val_loss: 1.8491 - val_mean_absolute_error: 0.6335\n",
      "Epoch 83/500\n",
      "360/360 [==============================] - 0s 466us/step - loss: 0.9363 - mean_absolute_error: 0.3850 - val_loss: 1.9118 - val_mean_absolute_error: 0.6651\n",
      "Epoch 84/500\n",
      "360/360 [==============================] - 0s 446us/step - loss: 0.9147 - mean_absolute_error: 0.3796 - val_loss: 1.7330 - val_mean_absolute_error: 0.6071\n",
      "Epoch 85/500\n",
      "360/360 [==============================] - 0s 423us/step - loss: 0.8477 - mean_absolute_error: 0.3412 - val_loss: 1.8809 - val_mean_absolute_error: 0.6372\n",
      "Epoch 86/500\n",
      "360/360 [==============================] - 0s 393us/step - loss: 0.9002 - mean_absolute_error: 0.3807 - val_loss: 1.9683 - val_mean_absolute_error: 0.6628\n",
      "Epoch 87/500\n",
      "360/360 [==============================] - 0s 441us/step - loss: 0.8837 - mean_absolute_error: 0.3795 - val_loss: 1.7742 - val_mean_absolute_error: 0.6265\n",
      "Epoch 88/500\n",
      "360/360 [==============================] - 0s 340us/step - loss: 0.9248 - mean_absolute_error: 0.3918 - val_loss: 1.7837 - val_mean_absolute_error: 0.6379\n",
      "Epoch 89/500\n",
      "360/360 [==============================] - 0s 460us/step - loss: 0.9383 - mean_absolute_error: 0.3941 - val_loss: 1.7755 - val_mean_absolute_error: 0.6499\n",
      "Epoch 90/500\n",
      "360/360 [==============================] - 0s 419us/step - loss: 1.0789 - mean_absolute_error: 0.4416 - val_loss: 2.3161 - val_mean_absolute_error: 0.7252\n",
      "Epoch 91/500\n",
      "360/360 [==============================] - 0s 399us/step - loss: 1.2818 - mean_absolute_error: 0.4988 - val_loss: 1.9810 - val_mean_absolute_error: 0.6904\n",
      "Epoch 92/500\n",
      "360/360 [==============================] - 0s 419us/step - loss: 0.8931 - mean_absolute_error: 0.3762 - val_loss: 1.6421 - val_mean_absolute_error: 0.5868\n",
      "Epoch 93/500\n",
      "360/360 [==============================] - 0s 434us/step - loss: 1.0118 - mean_absolute_error: 0.4279 - val_loss: 2.3450 - val_mean_absolute_error: 0.7559\n",
      "Epoch 94/500\n",
      "360/360 [==============================] - 0s 388us/step - loss: 1.0960 - mean_absolute_error: 0.4347 - val_loss: 2.4942 - val_mean_absolute_error: 0.7738\n",
      "Epoch 95/500\n",
      "360/360 [==============================] - 0s 409us/step - loss: 1.9708 - mean_absolute_error: 0.6889 - val_loss: 4.4025 - val_mean_absolute_error: 1.0869\n",
      "Epoch 96/500\n",
      "360/360 [==============================] - 0s 360us/step - loss: 1.4628 - mean_absolute_error: 0.5709 - val_loss: 1.8317 - val_mean_absolute_error: 0.6456\n",
      "Epoch 97/500\n",
      "360/360 [==============================] - 0s 502us/step - loss: 1.1212 - mean_absolute_error: 0.4426 - val_loss: 1.9320 - val_mean_absolute_error: 0.6687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/500\n",
      "360/360 [==============================] - 0s 428us/step - loss: 1.1117 - mean_absolute_error: 0.4589 - val_loss: 1.7481 - val_mean_absolute_error: 0.5932\n",
      "Epoch 99/500\n",
      "360/360 [==============================] - 0s 433us/step - loss: 0.9855 - mean_absolute_error: 0.4006 - val_loss: 1.8823 - val_mean_absolute_error: 0.6346\n",
      "Epoch 100/500\n",
      "360/360 [==============================] - 0s 398us/step - loss: 0.8764 - mean_absolute_error: 0.3855 - val_loss: 1.4840 - val_mean_absolute_error: 0.5885\n",
      "Epoch 101/500\n",
      "360/360 [==============================] - 0s 395us/step - loss: 1.1841 - mean_absolute_error: 0.4962 - val_loss: 3.4017 - val_mean_absolute_error: 1.0077\n",
      "Epoch 102/500\n",
      "360/360 [==============================] - 0s 433us/step - loss: 3.3817 - mean_absolute_error: 0.9329 - val_loss: 6.2308 - val_mean_absolute_error: 1.4259\n",
      "Epoch 103/500\n",
      "360/360 [==============================] - 0s 398us/step - loss: 2.0636 - mean_absolute_error: 0.6781 - val_loss: 3.0622 - val_mean_absolute_error: 0.9142\n",
      "Epoch 104/500\n",
      "360/360 [==============================] - 0s 405us/step - loss: 2.1404 - mean_absolute_error: 0.7001 - val_loss: 4.7586 - val_mean_absolute_error: 1.1899\n",
      "Epoch 105/500\n",
      "360/360 [==============================] - 0s 361us/step - loss: 1.2485 - mean_absolute_error: 0.4794 - val_loss: 1.9436 - val_mean_absolute_error: 0.7211\n",
      "Epoch 106/500\n",
      "360/360 [==============================] - 0s 513us/step - loss: 1.1668 - mean_absolute_error: 0.4397 - val_loss: 1.7001 - val_mean_absolute_error: 0.7148\n",
      "Epoch 107/500\n",
      "360/360 [==============================] - 0s 413us/step - loss: 0.9817 - mean_absolute_error: 0.4019 - val_loss: 1.8694 - val_mean_absolute_error: 0.6620\n",
      "Epoch 108/500\n",
      "360/360 [==============================] - 0s 388us/step - loss: 0.8190 - mean_absolute_error: 0.3508 - val_loss: 1.5316 - val_mean_absolute_error: 0.5559\n",
      "Epoch 109/500\n",
      "360/360 [==============================] - 0s 443us/step - loss: 0.6896 - mean_absolute_error: 0.2887 - val_loss: 1.4301 - val_mean_absolute_error: 0.5259\n",
      "Epoch 110/500\n",
      "360/360 [==============================] - 0s 412us/step - loss: 0.6637 - mean_absolute_error: 0.2790 - val_loss: 1.7284 - val_mean_absolute_error: 0.6225\n",
      "Epoch 111/500\n",
      "360/360 [==============================] - 0s 396us/step - loss: 0.9852 - mean_absolute_error: 0.4138 - val_loss: 3.5064 - val_mean_absolute_error: 0.9991\n",
      "Epoch 112/500\n",
      "360/360 [==============================] - 0s 360us/step - loss: 2.1160 - mean_absolute_error: 0.7012 - val_loss: 2.2181 - val_mean_absolute_error: 0.8590\n",
      "Epoch 113/500\n",
      "360/360 [==============================] - 0s 446us/step - loss: 1.0246 - mean_absolute_error: 0.4655 - val_loss: 2.0450 - val_mean_absolute_error: 0.6920\n",
      "Epoch 114/500\n",
      "360/360 [==============================] - 0s 450us/step - loss: 0.8528 - mean_absolute_error: 0.3632 - val_loss: 1.6673 - val_mean_absolute_error: 0.6030\n",
      "Epoch 115/500\n",
      "360/360 [==============================] - 0s 446us/step - loss: 2.3332 - mean_absolute_error: 0.7632 - val_loss: 5.6302 - val_mean_absolute_error: 1.2723\n",
      "Epoch 116/500\n",
      "360/360 [==============================] - 0s 416us/step - loss: 2.1831 - mean_absolute_error: 0.7268 - val_loss: 1.7551 - val_mean_absolute_error: 0.5906\n",
      "Epoch 117/500\n",
      "360/360 [==============================] - 0s 485us/step - loss: 1.0365 - mean_absolute_error: 0.4544 - val_loss: 3.0907 - val_mean_absolute_error: 0.8256\n",
      "Epoch 118/500\n",
      "360/360 [==============================] - 0s 425us/step - loss: 0.9451 - mean_absolute_error: 0.4132 - val_loss: 1.7337 - val_mean_absolute_error: 0.6557\n",
      "Epoch 119/500\n",
      "360/360 [==============================] - 0s 393us/step - loss: 1.2520 - mean_absolute_error: 0.4836 - val_loss: 1.6285 - val_mean_absolute_error: 0.6382\n",
      "Epoch 120/500\n",
      "360/360 [==============================] - 0s 378us/step - loss: 1.2521 - mean_absolute_error: 0.5048 - val_loss: 1.5918 - val_mean_absolute_error: 0.6105\n",
      "Epoch 121/500\n",
      "360/360 [==============================] - 0s 552us/step - loss: 1.0268 - mean_absolute_error: 0.4196 - val_loss: 1.6488 - val_mean_absolute_error: 0.6046\n",
      "Epoch 122/500\n",
      "360/360 [==============================] - 0s 492us/step - loss: 0.8203 - mean_absolute_error: 0.3713 - val_loss: 1.4966 - val_mean_absolute_error: 0.6010\n",
      "Epoch 123/500\n",
      "360/360 [==============================] - 0s 434us/step - loss: 0.6923 - mean_absolute_error: 0.3201 - val_loss: 1.4161 - val_mean_absolute_error: 0.5929\n",
      "Epoch 124/500\n",
      "360/360 [==============================] - 0s 444us/step - loss: 0.6096 - mean_absolute_error: 0.2731 - val_loss: 1.4429 - val_mean_absolute_error: 0.5551\n",
      "Epoch 125/500\n",
      "360/360 [==============================] - 0s 397us/step - loss: 0.6149 - mean_absolute_error: 0.2775 - val_loss: 1.6382 - val_mean_absolute_error: 0.5869\n",
      "Epoch 126/500\n",
      "360/360 [==============================] - 0s 454us/step - loss: 0.5774 - mean_absolute_error: 0.2666 - val_loss: 1.3917 - val_mean_absolute_error: 0.5353\n",
      "Epoch 127/500\n",
      "360/360 [==============================] - 0s 476us/step - loss: 0.6900 - mean_absolute_error: 0.3292 - val_loss: 1.4697 - val_mean_absolute_error: 0.5955\n",
      "Epoch 128/500\n",
      "360/360 [==============================] - 0s 523us/step - loss: 0.6802 - mean_absolute_error: 0.3354 - val_loss: 1.8759 - val_mean_absolute_error: 0.6455\n",
      "Epoch 129/500\n",
      "360/360 [==============================] - 0s 491us/step - loss: 0.7159 - mean_absolute_error: 0.3381 - val_loss: 1.2465 - val_mean_absolute_error: 0.6270\n",
      "Epoch 130/500\n",
      "360/360 [==============================] - 0s 368us/step - loss: 0.9072 - mean_absolute_error: 0.4332 - val_loss: 1.6769 - val_mean_absolute_error: 0.6887\n",
      "Epoch 131/500\n",
      "360/360 [==============================] - 0s 664us/step - loss: 1.2996 - mean_absolute_error: 0.5824 - val_loss: 5.1118 - val_mean_absolute_error: 1.0094\n",
      "Epoch 132/500\n",
      "360/360 [==============================] - 0s 480us/step - loss: 1.6289 - mean_absolute_error: 0.6230 - val_loss: 1.8668 - val_mean_absolute_error: 0.6926\n",
      "Epoch 133/500\n",
      "360/360 [==============================] - 0s 413us/step - loss: 1.5343 - mean_absolute_error: 0.5930 - val_loss: 2.5979 - val_mean_absolute_error: 0.8759\n",
      "Epoch 134/500\n",
      "360/360 [==============================] - 0s 555us/step - loss: 1.2669 - mean_absolute_error: 0.4891 - val_loss: 1.6713 - val_mean_absolute_error: 0.6297\n",
      "Epoch 135/500\n",
      "360/360 [==============================] - 0s 429us/step - loss: 1.7413 - mean_absolute_error: 0.6089 - val_loss: 1.6240 - val_mean_absolute_error: 0.6192\n",
      "Epoch 136/500\n",
      "360/360 [==============================] - 0s 377us/step - loss: 0.8169 - mean_absolute_error: 0.3860 - val_loss: 1.4267 - val_mean_absolute_error: 0.6590\n",
      "Epoch 137/500\n",
      "360/360 [==============================] - 0s 384us/step - loss: 0.6684 - mean_absolute_error: 0.3004 - val_loss: 1.3900 - val_mean_absolute_error: 0.5518\n",
      "Epoch 138/500\n",
      "360/360 [==============================] - 0s 385us/step - loss: 0.5818 - mean_absolute_error: 0.2773 - val_loss: 1.2587 - val_mean_absolute_error: 0.5425\n",
      "Epoch 139/500\n",
      "360/360 [==============================] - 0s 459us/step - loss: 0.5428 - mean_absolute_error: 0.2553 - val_loss: 1.2665 - val_mean_absolute_error: 0.5083\n",
      "Epoch 140/500\n",
      "360/360 [==============================] - 0s 563us/step - loss: 0.5781 - mean_absolute_error: 0.2849 - val_loss: 1.3861 - val_mean_absolute_error: 0.5537\n",
      "Epoch 141/500\n",
      "360/360 [==============================] - 0s 372us/step - loss: 0.6104 - mean_absolute_error: 0.2877 - val_loss: 1.7132 - val_mean_absolute_error: 0.6669\n",
      "Epoch 142/500\n",
      "360/360 [==============================] - 0s 355us/step - loss: 0.6665 - mean_absolute_error: 0.3220 - val_loss: 1.6547 - val_mean_absolute_error: 0.6035\n",
      "Epoch 143/500\n",
      "360/360 [==============================] - 0s 466us/step - loss: 0.8141 - mean_absolute_error: 0.3822 - val_loss: 1.5377 - val_mean_absolute_error: 0.5921\n",
      "Epoch 144/500\n",
      "360/360 [==============================] - 0s 434us/step - loss: 0.8590 - mean_absolute_error: 0.4312 - val_loss: 1.3892 - val_mean_absolute_error: 0.5775\n",
      "Epoch 145/500\n",
      "360/360 [==============================] - 0s 417us/step - loss: 0.8311 - mean_absolute_error: 0.4067 - val_loss: 2.6189 - val_mean_absolute_error: 0.8812\n",
      "Epoch 146/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360/360 [==============================] - 0s 387us/step - loss: 1.1766 - mean_absolute_error: 0.5209 - val_loss: 1.6567 - val_mean_absolute_error: 0.7733\n",
      "Epoch 147/500\n",
      "360/360 [==============================] - 0s 425us/step - loss: 0.9589 - mean_absolute_error: 0.4265 - val_loss: 1.0409 - val_mean_absolute_error: 0.4768\n",
      "Epoch 148/500\n",
      "360/360 [==============================] - 0s 445us/step - loss: 0.8974 - mean_absolute_error: 0.3938 - val_loss: 1.8456 - val_mean_absolute_error: 0.6645\n",
      "Epoch 149/500\n",
      "360/360 [==============================] - 0s 360us/step - loss: 0.9960 - mean_absolute_error: 0.4318 - val_loss: 1.6426 - val_mean_absolute_error: 0.6654\n",
      "Epoch 150/500\n",
      "360/360 [==============================] - 0s 483us/step - loss: 1.1830 - mean_absolute_error: 0.4781 - val_loss: 1.7993 - val_mean_absolute_error: 0.6640\n",
      "Epoch 151/500\n",
      "360/360 [==============================] - 0s 424us/step - loss: 0.7977 - mean_absolute_error: 0.3796 - val_loss: 1.1632 - val_mean_absolute_error: 0.5422\n",
      "Epoch 152/500\n",
      "360/360 [==============================] - 0s 429us/step - loss: 0.5994 - mean_absolute_error: 0.2966 - val_loss: 1.1018 - val_mean_absolute_error: 0.5404\n",
      "Epoch 153/500\n",
      "360/360 [==============================] - 0s 422us/step - loss: 0.5807 - mean_absolute_error: 0.2908 - val_loss: 1.2708 - val_mean_absolute_error: 0.5357\n",
      "Epoch 154/500\n",
      "360/360 [==============================] - 0s 360us/step - loss: 0.4947 - mean_absolute_error: 0.2431 - val_loss: 1.1907 - val_mean_absolute_error: 0.5468\n",
      "Epoch 155/500\n",
      "360/360 [==============================] - 0s 346us/step - loss: 0.4878 - mean_absolute_error: 0.2373 - val_loss: 1.1976 - val_mean_absolute_error: 0.5129\n",
      "Epoch 156/500\n",
      "360/360 [==============================] - 0s 385us/step - loss: 0.4868 - mean_absolute_error: 0.2456 - val_loss: 1.5457 - val_mean_absolute_error: 0.6628\n",
      "Epoch 157/500\n",
      "360/360 [==============================] - 0s 495us/step - loss: 0.5989 - mean_absolute_error: 0.2954 - val_loss: 1.3240 - val_mean_absolute_error: 0.5586\n",
      "Epoch 158/500\n",
      "360/360 [==============================] - 0s 481us/step - loss: 0.5908 - mean_absolute_error: 0.3119 - val_loss: 1.3570 - val_mean_absolute_error: 0.5803\n",
      "Epoch 159/500\n",
      "360/360 [==============================] - 0s 407us/step - loss: 1.0313 - mean_absolute_error: 0.4818 - val_loss: 1.4066 - val_mean_absolute_error: 0.6442\n",
      "Epoch 160/500\n",
      "360/360 [==============================] - 0s 422us/step - loss: 0.8327 - mean_absolute_error: 0.3969 - val_loss: 1.3671 - val_mean_absolute_error: 0.6312\n",
      "Epoch 161/500\n",
      "360/360 [==============================] - 0s 452us/step - loss: 1.4306 - mean_absolute_error: 0.5856 - val_loss: 2.9307 - val_mean_absolute_error: 0.8454\n",
      "Epoch 162/500\n",
      "360/360 [==============================] - 0s 500us/step - loss: 1.2782 - mean_absolute_error: 0.5452 - val_loss: 1.5325 - val_mean_absolute_error: 0.7747\n",
      "Epoch 163/500\n",
      "360/360 [==============================] - 0s 473us/step - loss: 1.1175 - mean_absolute_error: 0.4841 - val_loss: 1.1276 - val_mean_absolute_error: 0.5291\n",
      "Epoch 164/500\n",
      "360/360 [==============================] - 0s 349us/step - loss: 0.7993 - mean_absolute_error: 0.3789 - val_loss: 1.4166 - val_mean_absolute_error: 0.6206\n",
      "Epoch 165/500\n",
      "360/360 [==============================] - 0s 490us/step - loss: 0.6379 - mean_absolute_error: 0.3119 - val_loss: 1.8902 - val_mean_absolute_error: 0.7176\n",
      "Epoch 166/500\n",
      "360/360 [==============================] - 0s 446us/step - loss: 0.8285 - mean_absolute_error: 0.4109 - val_loss: 1.0264 - val_mean_absolute_error: 0.5409\n",
      "Epoch 167/500\n",
      "360/360 [==============================] - 0s 563us/step - loss: 0.9327 - mean_absolute_error: 0.4171 - val_loss: 1.0167 - val_mean_absolute_error: 0.4768\n",
      "Epoch 168/500\n",
      "360/360 [==============================] - 0s 502us/step - loss: 0.7014 - mean_absolute_error: 0.3478 - val_loss: 1.1768 - val_mean_absolute_error: 0.5569\n",
      "Epoch 169/500\n",
      "360/360 [==============================] - 0s 517us/step - loss: 0.7798 - mean_absolute_error: 0.3989 - val_loss: 1.9804 - val_mean_absolute_error: 0.6522\n",
      "Epoch 170/500\n",
      "360/360 [==============================] - 0s 441us/step - loss: 0.6274 - mean_absolute_error: 0.3240 - val_loss: 1.0397 - val_mean_absolute_error: 0.4892\n",
      "Epoch 171/500\n",
      "360/360 [==============================] - 0s 370us/step - loss: 0.6546 - mean_absolute_error: 0.3276 - val_loss: 1.2382 - val_mean_absolute_error: 0.5448\n",
      "Epoch 172/500\n",
      "360/360 [==============================] - 0s 507us/step - loss: 0.8788 - mean_absolute_error: 0.4376 - val_loss: 4.5368 - val_mean_absolute_error: 1.1003\n",
      "Epoch 173/500\n",
      "360/360 [==============================] - 0s 403us/step - loss: 1.2362 - mean_absolute_error: 0.6179 - val_loss: 1.2248 - val_mean_absolute_error: 0.6030\n",
      "Epoch 174/500\n",
      "360/360 [==============================] - 0s 363us/step - loss: 0.9476 - mean_absolute_error: 0.4468 - val_loss: 1.4109 - val_mean_absolute_error: 0.7194\n",
      "Epoch 175/500\n",
      "360/360 [==============================] - 0s 490us/step - loss: 0.8029 - mean_absolute_error: 0.4127 - val_loss: 1.0078 - val_mean_absolute_error: 0.4681\n",
      "Epoch 176/500\n",
      "360/360 [==============================] - 0s 396us/step - loss: 0.5097 - mean_absolute_error: 0.2612 - val_loss: 1.1375 - val_mean_absolute_error: 0.5203\n",
      "Epoch 177/500\n",
      "360/360 [==============================] - 0s 432us/step - loss: 0.6564 - mean_absolute_error: 0.3395 - val_loss: 1.0068 - val_mean_absolute_error: 0.5062\n",
      "Epoch 178/500\n",
      "360/360 [==============================] - 0s 388us/step - loss: 0.5303 - mean_absolute_error: 0.2681 - val_loss: 1.1200 - val_mean_absolute_error: 0.5232\n",
      "Epoch 179/500\n",
      "360/360 [==============================] - 0s 372us/step - loss: 0.5137 - mean_absolute_error: 0.2619 - val_loss: 1.2028 - val_mean_absolute_error: 0.5520\n",
      "Epoch 180/500\n",
      "360/360 [==============================] - 0s 425us/step - loss: 0.7002 - mean_absolute_error: 0.3718 - val_loss: 1.5085 - val_mean_absolute_error: 0.5805\n",
      "Epoch 181/500\n",
      "360/360 [==============================] - 0s 542us/step - loss: 0.9994 - mean_absolute_error: 0.5001 - val_loss: 2.0516 - val_mean_absolute_error: 0.6892\n",
      "Epoch 182/500\n",
      "360/360 [==============================] - 0s 474us/step - loss: 1.1004 - mean_absolute_error: 0.4959 - val_loss: 1.5728 - val_mean_absolute_error: 0.7547\n",
      "Epoch 183/500\n",
      "360/360 [==============================] - 0s 416us/step - loss: 0.7805 - mean_absolute_error: 0.4037 - val_loss: 1.2659 - val_mean_absolute_error: 0.5807\n",
      "Epoch 184/500\n",
      "360/360 [==============================] - 0s 500us/step - loss: 0.7575 - mean_absolute_error: 0.4000 - val_loss: 1.6105 - val_mean_absolute_error: 0.6223\n",
      "Epoch 185/500\n",
      "360/360 [==============================] - 0s 460us/step - loss: 0.5061 - mean_absolute_error: 0.2580 - val_loss: 1.1355 - val_mean_absolute_error: 0.5490\n",
      "Epoch 186/500\n",
      "360/360 [==============================] - 0s 451us/step - loss: 0.4347 - mean_absolute_error: 0.2318 - val_loss: 0.9838 - val_mean_absolute_error: 0.4959\n",
      "Epoch 187/500\n",
      "360/360 [==============================] - 0s 577us/step - loss: 0.4519 - mean_absolute_error: 0.2479 - val_loss: 1.1090 - val_mean_absolute_error: 0.5196\n",
      "Epoch 188/500\n",
      "360/360 [==============================] - 0s 717us/step - loss: 0.4740 - mean_absolute_error: 0.2560 - val_loss: 1.0451 - val_mean_absolute_error: 0.5534\n",
      "Epoch 189/500\n",
      "360/360 [==============================] - 0s 603us/step - loss: 0.4862 - mean_absolute_error: 0.2784 - val_loss: 1.2559 - val_mean_absolute_error: 0.5408\n",
      "Epoch 190/500\n",
      "360/360 [==============================] - 0s 424us/step - loss: 0.6056 - mean_absolute_error: 0.3491 - val_loss: 1.2488 - val_mean_absolute_error: 0.6362\n",
      "Epoch 191/500\n",
      "360/360 [==============================] - 0s 366us/step - loss: 0.5409 - mean_absolute_error: 0.3127 - val_loss: 0.9717 - val_mean_absolute_error: 0.5375\n",
      "Epoch 192/500\n",
      "360/360 [==============================] - 0s 397us/step - loss: 0.4794 - mean_absolute_error: 0.2722 - val_loss: 1.0208 - val_mean_absolute_error: 0.5102\n",
      "Epoch 193/500\n",
      "360/360 [==============================] - 0s 388us/step - loss: 0.5028 - mean_absolute_error: 0.2655 - val_loss: 1.0082 - val_mean_absolute_error: 0.5152\n",
      "Epoch 194/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360/360 [==============================] - 0s 388us/step - loss: 0.8180 - mean_absolute_error: 0.3685 - val_loss: 2.3461 - val_mean_absolute_error: 0.7327\n",
      "Epoch 195/500\n",
      "360/360 [==============================] - 0s 374us/step - loss: 2.6395 - mean_absolute_error: 0.8373 - val_loss: 5.0439 - val_mean_absolute_error: 1.1544\n",
      "Epoch 196/500\n",
      "360/360 [==============================] - 0s 346us/step - loss: 1.6533 - mean_absolute_error: 0.6358 - val_loss: 1.0681 - val_mean_absolute_error: 0.5397\n",
      "Epoch 197/500\n",
      "360/360 [==============================] - 0s 325us/step - loss: 0.7651 - mean_absolute_error: 0.3639 - val_loss: 1.6864 - val_mean_absolute_error: 0.7400\n",
      "Epoch 198/500\n",
      "360/360 [==============================] - 0s 336us/step - loss: 0.6200 - mean_absolute_error: 0.3298 - val_loss: 1.0268 - val_mean_absolute_error: 0.5275\n",
      "Epoch 199/500\n",
      "360/360 [==============================] - 0s 350us/step - loss: 0.4675 - mean_absolute_error: 0.2454 - val_loss: 1.0270 - val_mean_absolute_error: 0.4675\n",
      "Epoch 200/500\n",
      "360/360 [==============================] - 0s 352us/step - loss: 0.4408 - mean_absolute_error: 0.2314 - val_loss: 0.8995 - val_mean_absolute_error: 0.4731\n",
      "Epoch 201/500\n",
      "360/360 [==============================] - 0s 331us/step - loss: 0.4054 - mean_absolute_error: 0.2182 - val_loss: 1.0002 - val_mean_absolute_error: 0.5065\n",
      "Epoch 202/500\n",
      "360/360 [==============================] - 0s 331us/step - loss: 0.3900 - mean_absolute_error: 0.2088 - val_loss: 0.9122 - val_mean_absolute_error: 0.4927\n",
      "Epoch 203/500\n",
      "360/360 [==============================] - 0s 564us/step - loss: 0.3825 - mean_absolute_error: 0.2041 - val_loss: 0.8981 - val_mean_absolute_error: 0.4624\n",
      "Epoch 204/500\n",
      "360/360 [==============================] - 0s 473us/step - loss: 0.3798 - mean_absolute_error: 0.2022 - val_loss: 0.9357 - val_mean_absolute_error: 0.5146\n",
      "Epoch 205/500\n",
      "360/360 [==============================] - 0s 353us/step - loss: 0.3791 - mean_absolute_error: 0.2047 - val_loss: 0.8702 - val_mean_absolute_error: 0.5126\n",
      "Epoch 206/500\n",
      "360/360 [==============================] - 0s 342us/step - loss: 0.4125 - mean_absolute_error: 0.2252 - val_loss: 1.1738 - val_mean_absolute_error: 0.5505\n",
      "Epoch 207/500\n",
      "360/360 [==============================] - 0s 351us/step - loss: 0.5098 - mean_absolute_error: 0.2909 - val_loss: 1.2687 - val_mean_absolute_error: 0.5506\n",
      "Epoch 208/500\n",
      "360/360 [==============================] - 0s 369us/step - loss: 0.5790 - mean_absolute_error: 0.3347 - val_loss: 1.0571 - val_mean_absolute_error: 0.5441\n",
      "Epoch 209/500\n",
      "360/360 [==============================] - 0s 717us/step - loss: 0.5145 - mean_absolute_error: 0.3011 - val_loss: 1.2442 - val_mean_absolute_error: 0.5745\n",
      "Epoch 210/500\n",
      "360/360 [==============================] - 0s 479us/step - loss: 2.1848 - mean_absolute_error: 0.7227 - val_loss: 3.6399 - val_mean_absolute_error: 1.0242\n",
      "Epoch 211/500\n",
      "360/360 [==============================] - 0s 350us/step - loss: 1.1026 - mean_absolute_error: 0.5299 - val_loss: 0.8629 - val_mean_absolute_error: 0.4950\n",
      "Epoch 212/500\n",
      "360/360 [==============================] - 0s 340us/step - loss: 0.4868 - mean_absolute_error: 0.2703 - val_loss: 1.0619 - val_mean_absolute_error: 0.5255\n",
      "Epoch 213/500\n",
      "360/360 [==============================] - 0s 487us/step - loss: 0.4293 - mean_absolute_error: 0.2351 - val_loss: 0.9008 - val_mean_absolute_error: 0.4980\n",
      "Epoch 214/500\n",
      "360/360 [==============================] - 0s 459us/step - loss: 0.3907 - mean_absolute_error: 0.2091 - val_loss: 0.9445 - val_mean_absolute_error: 0.5095\n",
      "Epoch 215/500\n",
      "360/360 [==============================] - 0s 400us/step - loss: 0.3552 - mean_absolute_error: 0.1872 - val_loss: 1.0020 - val_mean_absolute_error: 0.5087\n",
      "Epoch 216/500\n",
      "360/360 [==============================] - 0s 370us/step - loss: 0.3391 - mean_absolute_error: 0.1715 - val_loss: 0.8287 - val_mean_absolute_error: 0.4692\n",
      "Epoch 217/500\n",
      "360/360 [==============================] - 0s 385us/step - loss: 0.3610 - mean_absolute_error: 0.1901 - val_loss: 1.1836 - val_mean_absolute_error: 0.5556\n",
      "Epoch 218/500\n",
      "360/360 [==============================] - 0s 429us/step - loss: 0.4330 - mean_absolute_error: 0.2453 - val_loss: 0.9646 - val_mean_absolute_error: 0.5031\n",
      "Epoch 219/500\n",
      "360/360 [==============================] - 0s 446us/step - loss: 1.2753 - mean_absolute_error: 0.5632 - val_loss: 1.4469 - val_mean_absolute_error: 0.6597\n",
      "Epoch 220/500\n",
      "360/360 [==============================] - 0s 438us/step - loss: 0.8928 - mean_absolute_error: 0.4646 - val_loss: 0.9788 - val_mean_absolute_error: 0.5828\n",
      "Epoch 221/500\n",
      "360/360 [==============================] - 0s 414us/step - loss: 0.4927 - mean_absolute_error: 0.3095 - val_loss: 0.9373 - val_mean_absolute_error: 0.4997\n",
      "Epoch 222/500\n",
      "360/360 [==============================] - 0s 436us/step - loss: 0.5931 - mean_absolute_error: 0.3258 - val_loss: 1.0864 - val_mean_absolute_error: 0.5678\n",
      "Epoch 223/500\n",
      "360/360 [==============================] - 0s 403us/step - loss: 0.3977 - mean_absolute_error: 0.2294 - val_loss: 1.1089 - val_mean_absolute_error: 0.5891\n",
      "Epoch 224/500\n",
      "360/360 [==============================] - 0s 505us/step - loss: 0.4577 - mean_absolute_error: 0.2589 - val_loss: 0.9172 - val_mean_absolute_error: 0.5539\n",
      "Epoch 225/500\n",
      "360/360 [==============================] - 0s 533us/step - loss: 0.3537 - mean_absolute_error: 0.1982 - val_loss: 0.8340 - val_mean_absolute_error: 0.4815\n",
      "Epoch 226/500\n",
      "360/360 [==============================] - 0s 564us/step - loss: 0.3305 - mean_absolute_error: 0.1794 - val_loss: 0.8703 - val_mean_absolute_error: 0.4836\n",
      "Epoch 227/500\n",
      "360/360 [==============================] - 0s 397us/step - loss: 0.3085 - mean_absolute_error: 0.1709 - val_loss: 0.9383 - val_mean_absolute_error: 0.5044\n",
      "Epoch 228/500\n",
      "360/360 [==============================] - 0s 358us/step - loss: 0.3018 - mean_absolute_error: 0.1617 - val_loss: 0.8686 - val_mean_absolute_error: 0.5055\n",
      "Epoch 229/500\n",
      "360/360 [==============================] - 0s 680us/step - loss: 0.3041 - mean_absolute_error: 0.1640 - val_loss: 0.9290 - val_mean_absolute_error: 0.5104\n",
      "Epoch 230/500\n",
      "360/360 [==============================] - 0s 383us/step - loss: 0.3145 - mean_absolute_error: 0.1810 - val_loss: 0.8829 - val_mean_absolute_error: 0.5118\n",
      "Epoch 231/500\n",
      "360/360 [==============================] - 0s 411us/step - loss: 0.3632 - mean_absolute_error: 0.2397 - val_loss: 1.0157 - val_mean_absolute_error: 0.5296\n",
      "Epoch 232/500\n",
      "360/360 [==============================] - 0s 353us/step - loss: 0.9765 - mean_absolute_error: 0.4506 - val_loss: 1.0423 - val_mean_absolute_error: 0.6148\n",
      "Epoch 233/500\n",
      "360/360 [==============================] - 0s 435us/step - loss: 1.3011 - mean_absolute_error: 0.5520 - val_loss: 0.8132 - val_mean_absolute_error: 0.4797\n",
      "Epoch 234/500\n",
      "360/360 [==============================] - 0s 509us/step - loss: 0.7877 - mean_absolute_error: 0.3954 - val_loss: 1.1985 - val_mean_absolute_error: 0.6380\n",
      "Epoch 235/500\n",
      "360/360 [==============================] - 0s 511us/step - loss: 0.4880 - mean_absolute_error: 0.3031 - val_loss: 0.8160 - val_mean_absolute_error: 0.5110\n",
      "Epoch 236/500\n",
      "360/360 [==============================] - 0s 576us/step - loss: 0.4084 - mean_absolute_error: 0.2516 - val_loss: 0.9535 - val_mean_absolute_error: 0.5116\n",
      "Epoch 237/500\n",
      "360/360 [==============================] - 0s 559us/step - loss: 0.3813 - mean_absolute_error: 0.2272 - val_loss: 0.9302 - val_mean_absolute_error: 0.4924\n",
      "Epoch 238/500\n",
      "360/360 [==============================] - 0s 412us/step - loss: 0.3310 - mean_absolute_error: 0.1959 - val_loss: 0.7665 - val_mean_absolute_error: 0.4720\n",
      "Epoch 239/500\n",
      "360/360 [==============================] - 0s 391us/step - loss: 0.3582 - mean_absolute_error: 0.2129 - val_loss: 0.7418 - val_mean_absolute_error: 0.4348\n",
      "Epoch 240/500\n",
      "360/360 [==============================] - 0s 573us/step - loss: 0.4226 - mean_absolute_error: 0.2668 - val_loss: 0.9914 - val_mean_absolute_error: 0.5415\n",
      "Epoch 241/500\n",
      "360/360 [==============================] - 0s 451us/step - loss: 0.3257 - mean_absolute_error: 0.1901 - val_loss: 0.8763 - val_mean_absolute_error: 0.4702\n",
      "Epoch 242/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360/360 [==============================] - 0s 495us/step - loss: 0.3575 - mean_absolute_error: 0.2133 - val_loss: 1.1163 - val_mean_absolute_error: 0.5692\n",
      "Epoch 243/500\n",
      "360/360 [==============================] - 0s 428us/step - loss: 0.3536 - mean_absolute_error: 0.2285 - val_loss: 0.8768 - val_mean_absolute_error: 0.4877\n",
      "Epoch 244/500\n",
      "360/360 [==============================] - 0s 491us/step - loss: 0.3633 - mean_absolute_error: 0.2357 - val_loss: 0.9182 - val_mean_absolute_error: 0.5392\n",
      "Epoch 245/500\n",
      "360/360 [==============================] - 0s 669us/step - loss: 0.3524 - mean_absolute_error: 0.2158 - val_loss: 0.8466 - val_mean_absolute_error: 0.4930\n",
      "Epoch 246/500\n",
      "360/360 [==============================] - 0s 611us/step - loss: 0.9795 - mean_absolute_error: 0.4501 - val_loss: 1.0862 - val_mean_absolute_error: 0.6417\n",
      "Epoch 247/500\n",
      "360/360 [==============================] - 0s 418us/step - loss: 1.2115 - mean_absolute_error: 0.5211 - val_loss: 1.7950 - val_mean_absolute_error: 0.8465\n",
      "Epoch 248/500\n",
      "360/360 [==============================] - 0s 396us/step - loss: 3.1894 - mean_absolute_error: 0.9053 - val_loss: 2.0121 - val_mean_absolute_error: 0.8120\n",
      "Epoch 249/500\n",
      "360/360 [==============================] - 0s 418us/step - loss: 1.4484 - mean_absolute_error: 0.6290 - val_loss: 1.1923 - val_mean_absolute_error: 0.6971\n",
      "Epoch 250/500\n",
      "360/360 [==============================] - 0s 455us/step - loss: 0.6018 - mean_absolute_error: 0.3533 - val_loss: 0.8459 - val_mean_absolute_error: 0.5460\n",
      "Epoch 251/500\n",
      "360/360 [==============================] - 0s 594us/step - loss: 0.4234 - mean_absolute_error: 0.2650 - val_loss: 0.8655 - val_mean_absolute_error: 0.5088\n",
      "Epoch 252/500\n",
      "360/360 [==============================] - 0s 540us/step - loss: 0.3674 - mean_absolute_error: 0.2358 - val_loss: 0.7990 - val_mean_absolute_error: 0.4823\n",
      "Epoch 253/500\n",
      "360/360 [==============================] - 0s 500us/step - loss: 0.3294 - mean_absolute_error: 0.1987 - val_loss: 0.8190 - val_mean_absolute_error: 0.4819\n",
      "Epoch 254/500\n",
      "360/360 [==============================] - 0s 489us/step - loss: 0.3649 - mean_absolute_error: 0.2115 - val_loss: 0.8570 - val_mean_absolute_error: 0.5045\n",
      "Epoch 255/500\n",
      "360/360 [==============================] - 0s 482us/step - loss: 0.3122 - mean_absolute_error: 0.1796 - val_loss: 0.9234 - val_mean_absolute_error: 0.5061\n",
      "Epoch 256/500\n",
      "360/360 [==============================] - 0s 453us/step - loss: 0.3003 - mean_absolute_error: 0.1724 - val_loss: 0.9227 - val_mean_absolute_error: 0.5404\n",
      "Epoch 257/500\n",
      "360/360 [==============================] - 0s 387us/step - loss: 0.2924 - mean_absolute_error: 0.1737 - val_loss: 0.8572 - val_mean_absolute_error: 0.5165\n",
      "Epoch 258/500\n",
      "360/360 [==============================] - 0s 352us/step - loss: 0.2803 - mean_absolute_error: 0.1610 - val_loss: 0.8085 - val_mean_absolute_error: 0.4847\n",
      "Epoch 259/500\n",
      "360/360 [==============================] - 0s 449us/step - loss: 0.2734 - mean_absolute_error: 0.1571 - val_loss: 0.7675 - val_mean_absolute_error: 0.4757\n",
      "Epoch 260/500\n",
      "360/360 [==============================] - 0s 403us/step - loss: 0.2652 - mean_absolute_error: 0.1487 - val_loss: 0.8076 - val_mean_absolute_error: 0.4781\n",
      "Epoch 261/500\n",
      "360/360 [==============================] - 0s 462us/step - loss: 0.2899 - mean_absolute_error: 0.1849 - val_loss: 1.0462 - val_mean_absolute_error: 0.5926\n",
      "Epoch 262/500\n",
      "360/360 [==============================] - 0s 410us/step - loss: 0.3088 - mean_absolute_error: 0.1975 - val_loss: 0.8832 - val_mean_absolute_error: 0.4995\n",
      "Epoch 263/500\n",
      "360/360 [==============================] - 0s 414us/step - loss: 0.3220 - mean_absolute_error: 0.1929 - val_loss: 0.7812 - val_mean_absolute_error: 0.4789\n",
      "Epoch 264/500\n",
      "360/360 [==============================] - 0s 416us/step - loss: 0.2919 - mean_absolute_error: 0.1777 - val_loss: 0.8940 - val_mean_absolute_error: 0.5188\n",
      "Epoch 265/500\n",
      "360/360 [==============================] - 0s 406us/step - loss: 0.3088 - mean_absolute_error: 0.1997 - val_loss: 0.8575 - val_mean_absolute_error: 0.4748\n",
      "Epoch 266/500\n",
      "360/360 [==============================] - 0s 359us/step - loss: 0.3582 - mean_absolute_error: 0.2400 - val_loss: 0.8281 - val_mean_absolute_error: 0.4958\n",
      "Epoch 267/500\n",
      "360/360 [==============================] - 0s 467us/step - loss: 0.5103 - mean_absolute_error: 0.3190 - val_loss: 1.2235 - val_mean_absolute_error: 0.5664\n",
      "Epoch 268/500\n",
      "360/360 [==============================] - 0s 417us/step - loss: 0.7155 - mean_absolute_error: 0.4067 - val_loss: 1.1151 - val_mean_absolute_error: 0.5871\n",
      "Epoch 269/500\n",
      "360/360 [==============================] - 0s 431us/step - loss: 0.6068 - mean_absolute_error: 0.3422 - val_loss: 1.1811 - val_mean_absolute_error: 0.6116\n",
      "Epoch 270/500\n",
      "360/360 [==============================] - 0s 420us/step - loss: 0.3858 - mean_absolute_error: 0.2622 - val_loss: 0.7953 - val_mean_absolute_error: 0.5000\n",
      "Epoch 271/500\n",
      "360/360 [==============================] - 0s 416us/step - loss: 0.5269 - mean_absolute_error: 0.3232 - val_loss: 2.0520 - val_mean_absolute_error: 0.8362\n",
      "Epoch 272/500\n",
      "360/360 [==============================] - 0s 431us/step - loss: 0.5605 - mean_absolute_error: 0.3508 - val_loss: 1.3094 - val_mean_absolute_error: 0.6439\n",
      "Epoch 273/500\n",
      "360/360 [==============================] - 0s 417us/step - loss: 1.2746 - mean_absolute_error: 0.5646 - val_loss: 2.2792 - val_mean_absolute_error: 1.0352\n",
      "Epoch 274/500\n",
      "360/360 [==============================] - 0s 411us/step - loss: 2.3918 - mean_absolute_error: 0.7885 - val_loss: 1.3510 - val_mean_absolute_error: 0.6887\n",
      "Epoch 275/500\n",
      "360/360 [==============================] - 0s 427us/step - loss: 0.7534 - mean_absolute_error: 0.3887 - val_loss: 0.9234 - val_mean_absolute_error: 0.5659\n",
      "Epoch 276/500\n",
      "360/360 [==============================] - 0s 416us/step - loss: 0.4920 - mean_absolute_error: 0.3158 - val_loss: 0.7640 - val_mean_absolute_error: 0.5079\n",
      "Epoch 277/500\n",
      "360/360 [==============================] - 0s 418us/step - loss: 0.3803 - mean_absolute_error: 0.2451 - val_loss: 0.7069 - val_mean_absolute_error: 0.4676\n",
      "Epoch 278/500\n",
      "360/360 [==============================] - 0s 383us/step - loss: 0.3028 - mean_absolute_error: 0.1883 - val_loss: 0.7429 - val_mean_absolute_error: 0.4510\n",
      "Epoch 279/500\n",
      "360/360 [==============================] - 0s 468us/step - loss: 0.2810 - mean_absolute_error: 0.1648 - val_loss: 0.6930 - val_mean_absolute_error: 0.4456\n",
      "Epoch 280/500\n",
      "360/360 [==============================] - 0s 477us/step - loss: 0.2686 - mean_absolute_error: 0.1587 - val_loss: 0.6856 - val_mean_absolute_error: 0.4436\n",
      "Epoch 281/500\n",
      "360/360 [==============================] - 0s 579us/step - loss: 0.2668 - mean_absolute_error: 0.1555 - val_loss: 0.7358 - val_mean_absolute_error: 0.4589\n",
      "Epoch 282/500\n",
      "360/360 [==============================] - 0s 537us/step - loss: 0.3415 - mean_absolute_error: 0.2181 - val_loss: 0.7898 - val_mean_absolute_error: 0.4839\n",
      "Epoch 283/500\n",
      "360/360 [==============================] - 0s 419us/step - loss: 0.3929 - mean_absolute_error: 0.2516 - val_loss: 0.7120 - val_mean_absolute_error: 0.4498\n",
      "Epoch 284/500\n",
      "360/360 [==============================] - 0s 574us/step - loss: 0.2919 - mean_absolute_error: 0.1883 - val_loss: 0.7879 - val_mean_absolute_error: 0.4580\n",
      "Epoch 285/500\n",
      "360/360 [==============================] - 0s 601us/step - loss: 0.2713 - mean_absolute_error: 0.1622 - val_loss: 0.7471 - val_mean_absolute_error: 0.4786\n",
      "Epoch 286/500\n",
      "360/360 [==============================] - 0s 545us/step - loss: 0.2811 - mean_absolute_error: 0.1732 - val_loss: 0.8030 - val_mean_absolute_error: 0.4815\n",
      "Epoch 287/500\n",
      "360/360 [==============================] - 0s 449us/step - loss: 0.2813 - mean_absolute_error: 0.1827 - val_loss: 0.8796 - val_mean_absolute_error: 0.4875\n",
      "Epoch 288/500\n",
      "360/360 [==============================] - 0s 483us/step - loss: 0.2675 - mean_absolute_error: 0.1693 - val_loss: 0.7102 - val_mean_absolute_error: 0.4462\n",
      "Epoch 289/500\n",
      "360/360 [==============================] - 0s 443us/step - loss: 0.2434 - mean_absolute_error: 0.1464 - val_loss: 0.6994 - val_mean_absolute_error: 0.4525\n",
      "Epoch 290/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360/360 [==============================] - 0s 445us/step - loss: 0.3582 - mean_absolute_error: 0.2348 - val_loss: 1.0415 - val_mean_absolute_error: 0.5300\n",
      "Epoch 291/500\n",
      "360/360 [==============================] - 0s 460us/step - loss: 0.3810 - mean_absolute_error: 0.2498 - val_loss: 0.7505 - val_mean_absolute_error: 0.4984\n",
      "Epoch 292/500\n",
      "360/360 [==============================] - 0s 395us/step - loss: 0.3092 - mean_absolute_error: 0.2072 - val_loss: 0.8135 - val_mean_absolute_error: 0.4692\n",
      "Epoch 293/500\n",
      "360/360 [==============================] - 0s 488us/step - loss: 0.3069 - mean_absolute_error: 0.1981 - val_loss: 0.8496 - val_mean_absolute_error: 0.4862\n",
      "Epoch 294/500\n",
      "360/360 [==============================] - 0s 573us/step - loss: 0.4799 - mean_absolute_error: 0.3031 - val_loss: 0.8936 - val_mean_absolute_error: 0.5193\n",
      "Epoch 295/500\n",
      "360/360 [==============================] - 0s 494us/step - loss: 0.6366 - mean_absolute_error: 0.3521 - val_loss: 0.8938 - val_mean_absolute_error: 0.5531\n",
      "Epoch 296/500\n",
      "360/360 [==============================] - 0s 421us/step - loss: 0.5710 - mean_absolute_error: 0.3299 - val_loss: 0.8207 - val_mean_absolute_error: 0.4889\n",
      "Epoch 297/500\n",
      "360/360 [==============================] - 0s 509us/step - loss: 0.5390 - mean_absolute_error: 0.3437 - val_loss: 0.7473 - val_mean_absolute_error: 0.4357\n",
      "Epoch 298/500\n",
      "360/360 [==============================] - 0s 507us/step - loss: 0.4621 - mean_absolute_error: 0.3010 - val_loss: 0.8323 - val_mean_absolute_error: 0.4853\n",
      "Epoch 299/500\n",
      "360/360 [==============================] - 0s 434us/step - loss: 0.6110 - mean_absolute_error: 0.3493 - val_loss: 1.0329 - val_mean_absolute_error: 0.5364\n",
      "Epoch 300/500\n",
      "360/360 [==============================] - 0s 413us/step - loss: 0.4067 - mean_absolute_error: 0.2661 - val_loss: 1.1881 - val_mean_absolute_error: 0.5635\n",
      "Epoch 301/500\n",
      "360/360 [==============================] - 0s 405us/step - loss: 0.7454 - mean_absolute_error: 0.3858 - val_loss: 0.6903 - val_mean_absolute_error: 0.4718\n",
      "Epoch 302/500\n",
      "360/360 [==============================] - 0s 421us/step - loss: 0.8007 - mean_absolute_error: 0.4278 - val_loss: 1.7843 - val_mean_absolute_error: 0.7431\n",
      "Epoch 303/500\n",
      "360/360 [==============================] - 0s 439us/step - loss: 0.5799 - mean_absolute_error: 0.3712 - val_loss: 1.2540 - val_mean_absolute_error: 0.6115\n",
      "Epoch 304/500\n",
      "360/360 [==============================] - 0s 388us/step - loss: 0.5379 - mean_absolute_error: 0.3025 - val_loss: 0.7961 - val_mean_absolute_error: 0.4422\n",
      "Epoch 305/500\n",
      "360/360 [==============================] - 0s 427us/step - loss: 0.4290 - mean_absolute_error: 0.2812 - val_loss: 0.7625 - val_mean_absolute_error: 0.4455\n",
      "Epoch 306/500\n",
      "360/360 [==============================] - 0s 469us/step - loss: 0.3244 - mean_absolute_error: 0.2203 - val_loss: 0.8098 - val_mean_absolute_error: 0.4747\n",
      "Epoch 307/500\n",
      "360/360 [==============================] - 0s 385us/step - loss: 0.3448 - mean_absolute_error: 0.2144 - val_loss: 0.9737 - val_mean_absolute_error: 0.5264\n",
      "Epoch 308/500\n",
      "360/360 [==============================] - 0s 362us/step - loss: 0.3286 - mean_absolute_error: 0.2303 - val_loss: 0.7763 - val_mean_absolute_error: 0.4540\n",
      "Epoch 309/500\n",
      "360/360 [==============================] - 0s 347us/step - loss: 0.2612 - mean_absolute_error: 0.1612 - val_loss: 0.7630 - val_mean_absolute_error: 0.4691\n",
      "Epoch 310/500\n",
      "360/360 [==============================] - 0s 381us/step - loss: 0.2449 - mean_absolute_error: 0.1467 - val_loss: 0.8478 - val_mean_absolute_error: 0.4766\n",
      "Epoch 311/500\n",
      "360/360 [==============================] - 0s 396us/step - loss: 0.2534 - mean_absolute_error: 0.1644 - val_loss: 0.8759 - val_mean_absolute_error: 0.4806\n",
      "Epoch 312/500\n",
      "360/360 [==============================] - 0s 394us/step - loss: 0.2579 - mean_absolute_error: 0.1755 - val_loss: 0.8109 - val_mean_absolute_error: 0.4957\n",
      "Epoch 313/500\n",
      "360/360 [==============================] - 0s 416us/step - loss: 0.2461 - mean_absolute_error: 0.1648 - val_loss: 1.0205 - val_mean_absolute_error: 0.5672\n",
      "Epoch 314/500\n",
      "360/360 [==============================] - 0s 416us/step - loss: 0.2430 - mean_absolute_error: 0.1635 - val_loss: 0.7884 - val_mean_absolute_error: 0.4846\n",
      "Epoch 315/500\n",
      "360/360 [==============================] - 0s 423us/step - loss: 0.2321 - mean_absolute_error: 0.1516 - val_loss: 0.7934 - val_mean_absolute_error: 0.4812\n",
      "Epoch 316/500\n",
      "360/360 [==============================] - 0s 396us/step - loss: 0.2397 - mean_absolute_error: 0.1610 - val_loss: 0.8249 - val_mean_absolute_error: 0.5262\n",
      "Epoch 317/500\n",
      "360/360 [==============================] - 0s 365us/step - loss: 0.2462 - mean_absolute_error: 0.1776 - val_loss: 0.8985 - val_mean_absolute_error: 0.4993\n",
      "Epoch 318/500\n",
      "360/360 [==============================] - 0s 362us/step - loss: 0.2352 - mean_absolute_error: 0.1554 - val_loss: 0.9721 - val_mean_absolute_error: 0.5359\n",
      "Epoch 319/500\n",
      "360/360 [==============================] - 0s 358us/step - loss: 0.3010 - mean_absolute_error: 0.2110 - val_loss: 0.8763 - val_mean_absolute_error: 0.5010\n",
      "Epoch 320/500\n",
      "360/360 [==============================] - 0s 335us/step - loss: 0.4424 - mean_absolute_error: 0.2896 - val_loss: 1.1750 - val_mean_absolute_error: 0.5819\n",
      "Epoch 321/500\n",
      "360/360 [==============================] - 0s 424us/step - loss: 0.6885 - mean_absolute_error: 0.4062 - val_loss: 0.9664 - val_mean_absolute_error: 0.5415\n",
      "Epoch 322/500\n",
      "360/360 [==============================] - 0s 393us/step - loss: 0.4401 - mean_absolute_error: 0.3000 - val_loss: 0.9118 - val_mean_absolute_error: 0.4947\n",
      "Epoch 323/500\n",
      "360/360 [==============================] - 0s 407us/step - loss: 0.3616 - mean_absolute_error: 0.2453 - val_loss: 0.7805 - val_mean_absolute_error: 0.4946\n",
      "Epoch 324/500\n",
      "360/360 [==============================] - 0s 398us/step - loss: 0.3078 - mean_absolute_error: 0.2085 - val_loss: 0.7979 - val_mean_absolute_error: 0.4792\n",
      "Epoch 325/500\n",
      "360/360 [==============================] - 0s 410us/step - loss: 0.3538 - mean_absolute_error: 0.2477 - val_loss: 1.0098 - val_mean_absolute_error: 0.5205\n",
      "Epoch 326/500\n",
      "360/360 [==============================] - 0s 371us/step - loss: 0.2970 - mean_absolute_error: 0.2265 - val_loss: 0.7827 - val_mean_absolute_error: 0.5076\n",
      "Epoch 327/500\n",
      "360/360 [==============================] - 0s 514us/step - loss: 0.2563 - mean_absolute_error: 0.1891 - val_loss: 0.7587 - val_mean_absolute_error: 0.5329\n",
      "Epoch 328/500\n",
      "360/360 [==============================] - 0s 474us/step - loss: 0.3775 - mean_absolute_error: 0.2626 - val_loss: 0.7635 - val_mean_absolute_error: 0.4624\n",
      "Epoch 329/500\n",
      "360/360 [==============================] - 0s 497us/step - loss: 0.4541 - mean_absolute_error: 0.2993 - val_loss: 0.7037 - val_mean_absolute_error: 0.4744\n",
      "Epoch 330/500\n",
      "360/360 [==============================] - 0s 427us/step - loss: 0.8707 - mean_absolute_error: 0.4487 - val_loss: 0.8292 - val_mean_absolute_error: 0.5588\n",
      "Epoch 331/500\n",
      "360/360 [==============================] - 0s 411us/step - loss: 1.1084 - mean_absolute_error: 0.5243 - val_loss: 1.1087 - val_mean_absolute_error: 0.5439\n",
      "Epoch 332/500\n",
      "360/360 [==============================] - 0s 482us/step - loss: 0.5171 - mean_absolute_error: 0.3412 - val_loss: 0.6283 - val_mean_absolute_error: 0.4722\n",
      "Epoch 333/500\n",
      "360/360 [==============================] - 0s 493us/step - loss: 0.4089 - mean_absolute_error: 0.2893 - val_loss: 0.7698 - val_mean_absolute_error: 0.4738\n",
      "Epoch 334/500\n",
      "360/360 [==============================] - 0s 448us/step - loss: 0.3846 - mean_absolute_error: 0.2627 - val_loss: 0.5747 - val_mean_absolute_error: 0.4298\n",
      "Epoch 335/500\n",
      "360/360 [==============================] - 0s 419us/step - loss: 0.3631 - mean_absolute_error: 0.2466 - val_loss: 0.6428 - val_mean_absolute_error: 0.4197\n",
      "Epoch 336/500\n",
      "360/360 [==============================] - 0s 398us/step - loss: 0.3434 - mean_absolute_error: 0.2529 - val_loss: 0.9116 - val_mean_absolute_error: 0.5611\n",
      "Epoch 337/500\n",
      "360/360 [==============================] - 0s 546us/step - loss: 0.3542 - mean_absolute_error: 0.2607 - val_loss: 0.6985 - val_mean_absolute_error: 0.4651\n",
      "Epoch 338/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360/360 [==============================] - 0s 502us/step - loss: 0.2907 - mean_absolute_error: 0.2111 - val_loss: 0.6737 - val_mean_absolute_error: 0.4509\n",
      "Epoch 339/500\n",
      "360/360 [==============================] - 0s 430us/step - loss: 0.2800 - mean_absolute_error: 0.2030 - val_loss: 0.7191 - val_mean_absolute_error: 0.4818\n",
      "Epoch 340/500\n",
      "360/360 [==============================] - 0s 352us/step - loss: 0.4222 - mean_absolute_error: 0.3077 - val_loss: 1.0005 - val_mean_absolute_error: 0.6789\n",
      "Epoch 341/500\n",
      "360/360 [==============================] - 0s 343us/step - loss: 0.5001 - mean_absolute_error: 0.3403 - val_loss: 0.9137 - val_mean_absolute_error: 0.5460\n",
      "Epoch 342/500\n",
      "360/360 [==============================] - 0s 369us/step - loss: 0.2756 - mean_absolute_error: 0.1940 - val_loss: 0.6908 - val_mean_absolute_error: 0.4720\n",
      "Epoch 343/500\n",
      "360/360 [==============================] - 0s 623us/step - loss: 0.3875 - mean_absolute_error: 0.2946 - val_loss: 0.7544 - val_mean_absolute_error: 0.4945\n",
      "Epoch 344/500\n",
      "360/360 [==============================] - 0s 329us/step - loss: 0.2840 - mean_absolute_error: 0.2095 - val_loss: 0.7255 - val_mean_absolute_error: 0.4812\n",
      "Epoch 345/500\n",
      "360/360 [==============================] - 0s 349us/step - loss: 0.2525 - mean_absolute_error: 0.1733 - val_loss: 0.6857 - val_mean_absolute_error: 0.4589\n",
      "Epoch 346/500\n",
      "360/360 [==============================] - 0s 481us/step - loss: 0.2186 - mean_absolute_error: 0.1464 - val_loss: 0.6343 - val_mean_absolute_error: 0.4328\n",
      "Epoch 347/500\n",
      "360/360 [==============================] - 0s 411us/step - loss: 0.2104 - mean_absolute_error: 0.1384 - val_loss: 0.7067 - val_mean_absolute_error: 0.4607\n",
      "Epoch 348/500\n",
      "360/360 [==============================] - 0s 392us/step - loss: 0.2181 - mean_absolute_error: 0.1535 - val_loss: 0.6514 - val_mean_absolute_error: 0.4325\n",
      "Epoch 349/500\n",
      "360/360 [==============================] - 0s 414us/step - loss: 0.2281 - mean_absolute_error: 0.1591 - val_loss: 0.9546 - val_mean_absolute_error: 0.5078\n",
      "Epoch 350/500\n",
      "360/360 [==============================] - 0s 402us/step - loss: 0.2684 - mean_absolute_error: 0.2287 - val_loss: 0.8566 - val_mean_absolute_error: 0.4838\n",
      "Epoch 351/500\n",
      "360/360 [==============================] - 0s 403us/step - loss: 0.2381 - mean_absolute_error: 0.1762 - val_loss: 0.6784 - val_mean_absolute_error: 0.4453\n",
      "Epoch 352/500\n",
      "360/360 [==============================] - 0s 372us/step - loss: 0.2445 - mean_absolute_error: 0.1871 - val_loss: 0.7167 - val_mean_absolute_error: 0.4725\n",
      "Epoch 353/500\n",
      "360/360 [==============================] - 0s 410us/step - loss: 0.3433 - mean_absolute_error: 0.2729 - val_loss: 0.6590 - val_mean_absolute_error: 0.4166\n",
      "Epoch 354/500\n",
      "360/360 [==============================] - 0s 439us/step - loss: 0.5469 - mean_absolute_error: 0.3208 - val_loss: 0.6281 - val_mean_absolute_error: 0.4414\n",
      "Epoch 355/500\n",
      "360/360 [==============================] - 0s 522us/step - loss: 0.4620 - mean_absolute_error: 0.2937 - val_loss: 1.4039 - val_mean_absolute_error: 0.6641\n",
      "Epoch 356/500\n",
      "360/360 [==============================] - 0s 437us/step - loss: 1.5606 - mean_absolute_error: 0.6890 - val_loss: 1.2410 - val_mean_absolute_error: 0.6377\n",
      "Epoch 357/500\n",
      "360/360 [==============================] - 0s 341us/step - loss: 1.0576 - mean_absolute_error: 0.5663 - val_loss: 1.4949 - val_mean_absolute_error: 0.6441\n",
      "Epoch 358/500\n",
      "360/360 [==============================] - 0s 351us/step - loss: 0.5412 - mean_absolute_error: 0.3296 - val_loss: 0.7838 - val_mean_absolute_error: 0.5231\n",
      "Epoch 359/500\n",
      "360/360 [==============================] - 0s 536us/step - loss: 0.2987 - mean_absolute_error: 0.2259 - val_loss: 0.7320 - val_mean_absolute_error: 0.4615\n",
      "Epoch 360/500\n",
      "360/360 [==============================] - 0s 517us/step - loss: 0.2325 - mean_absolute_error: 0.1661 - val_loss: 0.7415 - val_mean_absolute_error: 0.4872\n",
      "Epoch 361/500\n",
      "360/360 [==============================] - 0s 608us/step - loss: 0.2548 - mean_absolute_error: 0.1863 - val_loss: 1.0326 - val_mean_absolute_error: 0.5772\n",
      "Epoch 362/500\n",
      "360/360 [==============================] - 0s 449us/step - loss: 0.2948 - mean_absolute_error: 0.2276 - val_loss: 0.7813 - val_mean_absolute_error: 0.5125\n",
      "Epoch 363/500\n",
      "360/360 [==============================] - 0s 432us/step - loss: 0.2580 - mean_absolute_error: 0.1881 - val_loss: 0.7854 - val_mean_absolute_error: 0.5012\n",
      "Epoch 364/500\n",
      "360/360 [==============================] - 0s 520us/step - loss: 0.2338 - mean_absolute_error: 0.1670 - val_loss: 0.7454 - val_mean_absolute_error: 0.4920\n",
      "Epoch 365/500\n",
      "360/360 [==============================] - 0s 437us/step - loss: 0.2070 - mean_absolute_error: 0.1374 - val_loss: 0.6896 - val_mean_absolute_error: 0.4612\n",
      "Epoch 366/500\n",
      "360/360 [==============================] - 0s 430us/step - loss: 0.2173 - mean_absolute_error: 0.1562 - val_loss: 0.7246 - val_mean_absolute_error: 0.4914\n",
      "Epoch 367/500\n",
      "360/360 [==============================] - 0s 393us/step - loss: 0.2186 - mean_absolute_error: 0.1608 - val_loss: 0.6438 - val_mean_absolute_error: 0.4416\n",
      "Epoch 368/500\n",
      "360/360 [==============================] - 0s 529us/step - loss: 0.2074 - mean_absolute_error: 0.1463 - val_loss: 0.8851 - val_mean_absolute_error: 0.5287\n",
      "Epoch 369/500\n",
      "360/360 [==============================] - 0s 630us/step - loss: 0.2470 - mean_absolute_error: 0.1872 - val_loss: 0.8427 - val_mean_absolute_error: 0.5054\n",
      "Epoch 370/500\n",
      "360/360 [==============================] - 0s 492us/step - loss: 0.2281 - mean_absolute_error: 0.1797 - val_loss: 0.8214 - val_mean_absolute_error: 0.5258\n",
      "Epoch 371/500\n",
      "360/360 [==============================] - 0s 464us/step - loss: 0.2005 - mean_absolute_error: 0.1395 - val_loss: 0.7396 - val_mean_absolute_error: 0.4980\n",
      "Epoch 372/500\n",
      "360/360 [==============================] - 0s 642us/step - loss: 0.2361 - mean_absolute_error: 0.1829 - val_loss: 0.7680 - val_mean_absolute_error: 0.4857\n",
      "Epoch 373/500\n",
      "360/360 [==============================] - 0s 664us/step - loss: 0.3491 - mean_absolute_error: 0.2486 - val_loss: 0.7329 - val_mean_absolute_error: 0.4520\n",
      "Epoch 374/500\n",
      "360/360 [==============================] - 0s 726us/step - loss: 0.3078 - mean_absolute_error: 0.2271 - val_loss: 0.9729 - val_mean_absolute_error: 0.5332\n",
      "Epoch 375/500\n",
      "360/360 [==============================] - 0s 482us/step - loss: 0.2862 - mean_absolute_error: 0.2264 - val_loss: 0.6183 - val_mean_absolute_error: 0.4144\n",
      "Epoch 376/500\n",
      "360/360 [==============================] - 0s 659us/step - loss: 0.4008 - mean_absolute_error: 0.2775 - val_loss: 0.9723 - val_mean_absolute_error: 0.5251\n",
      "Epoch 377/500\n",
      "360/360 [==============================] - 0s 645us/step - loss: 0.4699 - mean_absolute_error: 0.3188 - val_loss: 1.3553 - val_mean_absolute_error: 0.6648\n",
      "Epoch 378/500\n",
      "360/360 [==============================] - 0s 504us/step - loss: 0.4561 - mean_absolute_error: 0.3393 - val_loss: 0.7800 - val_mean_absolute_error: 0.5079\n",
      "Epoch 379/500\n",
      "360/360 [==============================] - 0s 682us/step - loss: 0.3821 - mean_absolute_error: 0.2933 - val_loss: 1.0046 - val_mean_absolute_error: 0.5417\n",
      "Epoch 380/500\n",
      "360/360 [==============================] - 0s 557us/step - loss: 0.3932 - mean_absolute_error: 0.2900 - val_loss: 1.2536 - val_mean_absolute_error: 0.6335\n",
      "Epoch 381/500\n",
      "360/360 [==============================] - 0s 536us/step - loss: 0.8516 - mean_absolute_error: 0.4291 - val_loss: 1.0072 - val_mean_absolute_error: 0.5528\n",
      "Epoch 382/500\n",
      "360/360 [==============================] - 0s 532us/step - loss: 0.5745 - mean_absolute_error: 0.3582 - val_loss: 0.6541 - val_mean_absolute_error: 0.4142\n",
      "Epoch 383/500\n",
      "360/360 [==============================] - 0s 777us/step - loss: 0.3579 - mean_absolute_error: 0.2711 - val_loss: 0.7990 - val_mean_absolute_error: 0.5229\n",
      "Epoch 384/500\n",
      "360/360 [==============================] - 0s 578us/step - loss: 0.3308 - mean_absolute_error: 0.2582 - val_loss: 0.8543 - val_mean_absolute_error: 0.4797\n",
      "Epoch 385/500\n",
      "360/360 [==============================] - 0s 715us/step - loss: 0.2640 - mean_absolute_error: 0.2138 - val_loss: 0.6984 - val_mean_absolute_error: 0.4726\n",
      "Epoch 386/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360/360 [==============================] - 0s 587us/step - loss: 0.2133 - mean_absolute_error: 0.1486 - val_loss: 0.6408 - val_mean_absolute_error: 0.4594\n",
      "Epoch 387/500\n",
      "360/360 [==============================] - 0s 555us/step - loss: 0.1964 - mean_absolute_error: 0.1406 - val_loss: 0.7029 - val_mean_absolute_error: 0.4526\n",
      "Epoch 388/500\n",
      "360/360 [==============================] - 0s 701us/step - loss: 0.2313 - mean_absolute_error: 0.1819 - val_loss: 0.6270 - val_mean_absolute_error: 0.4523\n",
      "Epoch 389/500\n",
      "360/360 [==============================] - 0s 434us/step - loss: 0.1855 - mean_absolute_error: 0.1306 - val_loss: 0.5919 - val_mean_absolute_error: 0.4435\n",
      "Epoch 390/500\n",
      "360/360 [==============================] - 0s 472us/step - loss: 0.2379 - mean_absolute_error: 0.1972 - val_loss: 0.7351 - val_mean_absolute_error: 0.4971\n",
      "Epoch 391/500\n",
      "360/360 [==============================] - 0s 546us/step - loss: 0.2071 - mean_absolute_error: 0.1582 - val_loss: 0.6697 - val_mean_absolute_error: 0.4633\n",
      "Epoch 392/500\n",
      "360/360 [==============================] - 0s 478us/step - loss: 0.2899 - mean_absolute_error: 0.2257 - val_loss: 0.8828 - val_mean_absolute_error: 0.5008\n",
      "Epoch 393/500\n",
      "360/360 [==============================] - 0s 536us/step - loss: 0.3847 - mean_absolute_error: 0.2913 - val_loss: 1.2787 - val_mean_absolute_error: 0.6338\n",
      "Epoch 394/500\n",
      "360/360 [==============================] - 0s 534us/step - loss: 0.9641 - mean_absolute_error: 0.5006 - val_loss: 1.7860 - val_mean_absolute_error: 0.7985\n",
      "Epoch 395/500\n",
      "360/360 [==============================] - 0s 545us/step - loss: 0.6793 - mean_absolute_error: 0.3998 - val_loss: 1.1479 - val_mean_absolute_error: 0.5919\n",
      "Epoch 396/500\n",
      "360/360 [==============================] - 0s 484us/step - loss: 0.3904 - mean_absolute_error: 0.2876 - val_loss: 0.6742 - val_mean_absolute_error: 0.4490\n",
      "Epoch 397/500\n",
      "360/360 [==============================] - 0s 371us/step - loss: 0.3073 - mean_absolute_error: 0.2365 - val_loss: 0.6371 - val_mean_absolute_error: 0.4640\n",
      "Epoch 398/500\n",
      "360/360 [==============================] - 0s 455us/step - loss: 0.2476 - mean_absolute_error: 0.1918 - val_loss: 0.7887 - val_mean_absolute_error: 0.4976\n",
      "Epoch 399/500\n",
      "360/360 [==============================] - 0s 436us/step - loss: 0.2752 - mean_absolute_error: 0.2144 - val_loss: 0.6476 - val_mean_absolute_error: 0.4590\n",
      "Epoch 400/500\n",
      "360/360 [==============================] - 0s 525us/step - loss: 0.2711 - mean_absolute_error: 0.2101 - val_loss: 0.6373 - val_mean_absolute_error: 0.4540\n",
      "Epoch 401/500\n",
      "360/360 [==============================] - 0s 389us/step - loss: 0.2201 - mean_absolute_error: 0.1701 - val_loss: 0.7139 - val_mean_absolute_error: 0.4795\n",
      "Epoch 402/500\n",
      "360/360 [==============================] - 0s 353us/step - loss: 0.2163 - mean_absolute_error: 0.1599 - val_loss: 0.6787 - val_mean_absolute_error: 0.4734\n",
      "Epoch 403/500\n",
      "360/360 [==============================] - 0s 356us/step - loss: 0.1960 - mean_absolute_error: 0.1452 - val_loss: 0.6183 - val_mean_absolute_error: 0.4561\n",
      "Epoch 404/500\n",
      "360/360 [==============================] - 0s 445us/step - loss: 0.1767 - mean_absolute_error: 0.1219 - val_loss: 0.7219 - val_mean_absolute_error: 0.4746\n",
      "Epoch 405/500\n",
      "360/360 [==============================] - 0s 538us/step - loss: 0.1732 - mean_absolute_error: 0.1206 - val_loss: 0.6391 - val_mean_absolute_error: 0.4616\n",
      "Epoch 406/500\n",
      "360/360 [==============================] - 0s 335us/step - loss: 0.1796 - mean_absolute_error: 0.1314 - val_loss: 0.6577 - val_mean_absolute_error: 0.4772\n",
      "Epoch 407/500\n",
      "360/360 [==============================] - 0s 414us/step - loss: 0.1826 - mean_absolute_error: 0.1402 - val_loss: 0.8006 - val_mean_absolute_error: 0.4961\n",
      "Epoch 408/500\n",
      "360/360 [==============================] - 0s 413us/step - loss: 0.4024 - mean_absolute_error: 0.2946 - val_loss: 0.6576 - val_mean_absolute_error: 0.4776\n",
      "Epoch 409/500\n",
      "360/360 [==============================] - 0s 589us/step - loss: 0.3548 - mean_absolute_error: 0.2612 - val_loss: 0.9247 - val_mean_absolute_error: 0.4949\n",
      "Epoch 410/500\n",
      "360/360 [==============================] - 0s 450us/step - loss: 0.5531 - mean_absolute_error: 0.4030 - val_loss: 0.8338 - val_mean_absolute_error: 0.5442\n",
      "Epoch 411/500\n",
      "360/360 [==============================] - 0s 426us/step - loss: 0.4045 - mean_absolute_error: 0.2907 - val_loss: 1.4350 - val_mean_absolute_error: 0.6551\n",
      "Epoch 412/500\n",
      "360/360 [==============================] - 0s 439us/step - loss: 0.3924 - mean_absolute_error: 0.2856 - val_loss: 0.9393 - val_mean_absolute_error: 0.5449\n",
      "Epoch 413/500\n",
      "360/360 [==============================] - 0s 393us/step - loss: 0.3132 - mean_absolute_error: 0.2376 - val_loss: 0.7927 - val_mean_absolute_error: 0.5222\n",
      "Epoch 414/500\n",
      "360/360 [==============================] - 0s 439us/step - loss: 0.2805 - mean_absolute_error: 0.2220 - val_loss: 0.6771 - val_mean_absolute_error: 0.4825\n",
      "Epoch 415/500\n",
      "360/360 [==============================] - 0s 407us/step - loss: 0.3367 - mean_absolute_error: 0.2662 - val_loss: 0.8548 - val_mean_absolute_error: 0.5495\n",
      "Epoch 416/500\n",
      "360/360 [==============================] - 0s 392us/step - loss: 0.5659 - mean_absolute_error: 0.3812 - val_loss: 0.6524 - val_mean_absolute_error: 0.4404\n",
      "Epoch 417/500\n",
      "360/360 [==============================] - 0s 412us/step - loss: 0.3254 - mean_absolute_error: 0.2396 - val_loss: 0.6686 - val_mean_absolute_error: 0.4201\n",
      "Epoch 418/500\n",
      "360/360 [==============================] - 0s 352us/step - loss: 0.2402 - mean_absolute_error: 0.1848 - val_loss: 0.8417 - val_mean_absolute_error: 0.5117\n",
      "Epoch 419/500\n",
      "360/360 [==============================] - 0s 372us/step - loss: 0.2636 - mean_absolute_error: 0.2063 - val_loss: 0.8312 - val_mean_absolute_error: 0.4987\n",
      "Epoch 420/500\n",
      "360/360 [==============================] - 0s 435us/step - loss: 0.2416 - mean_absolute_error: 0.2094 - val_loss: 0.7274 - val_mean_absolute_error: 0.4840\n",
      "Epoch 421/500\n",
      "360/360 [==============================] - 0s 415us/step - loss: 0.2631 - mean_absolute_error: 0.2195 - val_loss: 0.6292 - val_mean_absolute_error: 0.4392\n",
      "Epoch 422/500\n",
      "360/360 [==============================] - 0s 404us/step - loss: 0.2068 - mean_absolute_error: 0.1751 - val_loss: 0.7332 - val_mean_absolute_error: 0.4869\n",
      "Epoch 423/500\n",
      "360/360 [==============================] - 0s 544us/step - loss: 0.2889 - mean_absolute_error: 0.2303 - val_loss: 0.6238 - val_mean_absolute_error: 0.4486\n",
      "Epoch 424/500\n",
      "360/360 [==============================] - 0s 462us/step - loss: 0.4660 - mean_absolute_error: 0.3428 - val_loss: 0.7781 - val_mean_absolute_error: 0.5319\n",
      "Epoch 425/500\n",
      "360/360 [==============================] - 0s 423us/step - loss: 0.5945 - mean_absolute_error: 0.3961 - val_loss: 1.0465 - val_mean_absolute_error: 0.5783\n",
      "Epoch 426/500\n",
      "360/360 [==============================] - 0s 370us/step - loss: 0.3334 - mean_absolute_error: 0.2647 - val_loss: 0.6452 - val_mean_absolute_error: 0.4718\n",
      "Epoch 427/500\n",
      "360/360 [==============================] - 0s 345us/step - loss: 0.2430 - mean_absolute_error: 0.1940 - val_loss: 0.6377 - val_mean_absolute_error: 0.4693\n",
      "Epoch 428/500\n",
      "360/360 [==============================] - 0s 409us/step - loss: 0.2011 - mean_absolute_error: 0.1661 - val_loss: 0.7173 - val_mean_absolute_error: 0.4942\n",
      "Epoch 429/500\n",
      "360/360 [==============================] - 0s 424us/step - loss: 0.3291 - mean_absolute_error: 0.2454 - val_loss: 1.1887 - val_mean_absolute_error: 0.6012\n",
      "Epoch 430/500\n",
      "360/360 [==============================] - 0s 335us/step - loss: 0.3652 - mean_absolute_error: 0.2726 - val_loss: 0.9275 - val_mean_absolute_error: 0.5514\n",
      "Epoch 431/500\n",
      "360/360 [==============================] - 0s 361us/step - loss: 0.3615 - mean_absolute_error: 0.2663 - val_loss: 0.9445 - val_mean_absolute_error: 0.5577\n",
      "Epoch 432/500\n",
      "360/360 [==============================] - 0s 359us/step - loss: 0.4086 - mean_absolute_error: 0.3093 - val_loss: 0.6293 - val_mean_absolute_error: 0.4740\n",
      "Epoch 433/500\n",
      "360/360 [==============================] - 0s 405us/step - loss: 0.5132 - mean_absolute_error: 0.3764 - val_loss: 0.6263 - val_mean_absolute_error: 0.4668\n",
      "Epoch 434/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360/360 [==============================] - 0s 389us/step - loss: 0.3880 - mean_absolute_error: 0.3024 - val_loss: 0.8232 - val_mean_absolute_error: 0.5265\n",
      "Epoch 435/500\n",
      "360/360 [==============================] - 0s 394us/step - loss: 0.2673 - mean_absolute_error: 0.1948 - val_loss: 0.7000 - val_mean_absolute_error: 0.4742\n",
      "Epoch 436/500\n",
      "360/360 [==============================] - 0s 404us/step - loss: 0.2349 - mean_absolute_error: 0.1890 - val_loss: 0.6671 - val_mean_absolute_error: 0.4596\n",
      "Epoch 437/500\n",
      "360/360 [==============================] - 0s 373us/step - loss: 0.1999 - mean_absolute_error: 0.1552 - val_loss: 0.7547 - val_mean_absolute_error: 0.4957\n",
      "Epoch 438/500\n",
      "360/360 [==============================] - 0s 392us/step - loss: 0.2025 - mean_absolute_error: 0.1557 - val_loss: 0.7762 - val_mean_absolute_error: 0.4912\n",
      "Epoch 439/500\n",
      "360/360 [==============================] - 0s 380us/step - loss: 0.1795 - mean_absolute_error: 0.1413 - val_loss: 0.7139 - val_mean_absolute_error: 0.5035\n",
      "Epoch 440/500\n",
      "360/360 [==============================] - 0s 389us/step - loss: 0.1728 - mean_absolute_error: 0.1312 - val_loss: 0.6874 - val_mean_absolute_error: 0.4884\n",
      "Epoch 441/500\n",
      "360/360 [==============================] - 0s 399us/step - loss: 0.1651 - mean_absolute_error: 0.1174 - val_loss: 0.7406 - val_mean_absolute_error: 0.4895\n",
      "Epoch 442/500\n",
      "360/360 [==============================] - 0s 379us/step - loss: 0.1700 - mean_absolute_error: 0.1300 - val_loss: 0.7019 - val_mean_absolute_error: 0.4992\n",
      "Epoch 443/500\n",
      "360/360 [==============================] - 0s 364us/step - loss: 0.2107 - mean_absolute_error: 0.1499 - val_loss: 0.7039 - val_mean_absolute_error: 0.4847\n",
      "Epoch 444/500\n",
      "360/360 [==============================] - 0s 373us/step - loss: 0.6428 - mean_absolute_error: 0.4345 - val_loss: 0.9419 - val_mean_absolute_error: 0.5868\n",
      "Epoch 445/500\n",
      "360/360 [==============================] - 0s 402us/step - loss: 0.3613 - mean_absolute_error: 0.3023 - val_loss: 0.9392 - val_mean_absolute_error: 0.5186\n",
      "Epoch 446/500\n",
      "360/360 [==============================] - 0s 514us/step - loss: 0.3855 - mean_absolute_error: 0.3193 - val_loss: 0.9330 - val_mean_absolute_error: 0.6009\n",
      "Epoch 447/500\n",
      "360/360 [==============================] - 0s 477us/step - loss: 0.2557 - mean_absolute_error: 0.2277 - val_loss: 0.6443 - val_mean_absolute_error: 0.4216\n",
      "Epoch 448/500\n",
      "360/360 [==============================] - 0s 454us/step - loss: 0.2426 - mean_absolute_error: 0.2045 - val_loss: 0.8554 - val_mean_absolute_error: 0.5347\n",
      "Epoch 449/500\n",
      "360/360 [==============================] - 0s 490us/step - loss: 0.2156 - mean_absolute_error: 0.1848 - val_loss: 0.5998 - val_mean_absolute_error: 0.4494\n",
      "Epoch 450/500\n",
      "360/360 [==============================] - 0s 435us/step - loss: 0.1983 - mean_absolute_error: 0.1583 - val_loss: 0.6062 - val_mean_absolute_error: 0.4483\n",
      "Epoch 451/500\n",
      "360/360 [==============================] - 0s 491us/step - loss: 0.2120 - mean_absolute_error: 0.1831 - val_loss: 0.5926 - val_mean_absolute_error: 0.4590\n",
      "Epoch 452/500\n",
      "360/360 [==============================] - 0s 421us/step - loss: 0.2082 - mean_absolute_error: 0.1853 - val_loss: 1.0199 - val_mean_absolute_error: 0.5423\n",
      "Epoch 453/500\n",
      "360/360 [==============================] - 0s 474us/step - loss: 0.3091 - mean_absolute_error: 0.2630 - val_loss: 0.8450 - val_mean_absolute_error: 0.5291\n",
      "Epoch 454/500\n",
      "360/360 [==============================] - 0s 457us/step - loss: 0.3602 - mean_absolute_error: 0.2850 - val_loss: 1.9250 - val_mean_absolute_error: 0.8268\n",
      "Epoch 455/500\n",
      "360/360 [==============================] - 0s 447us/step - loss: 0.8701 - mean_absolute_error: 0.4690 - val_loss: 5.0095 - val_mean_absolute_error: 1.1250\n",
      "Epoch 456/500\n",
      "360/360 [==============================] - 0s 516us/step - loss: 2.1821 - mean_absolute_error: 0.8002 - val_loss: 1.7110 - val_mean_absolute_error: 0.6710\n",
      "Epoch 457/500\n",
      "360/360 [==============================] - 0s 489us/step - loss: 0.8388 - mean_absolute_error: 0.4966 - val_loss: 0.9892 - val_mean_absolute_error: 0.6362\n",
      "Epoch 458/500\n",
      "360/360 [==============================] - 0s 417us/step - loss: 0.5200 - mean_absolute_error: 0.3747 - val_loss: 0.5262 - val_mean_absolute_error: 0.4208\n",
      "Epoch 459/500\n",
      "360/360 [==============================] - 0s 338us/step - loss: 0.3157 - mean_absolute_error: 0.2638 - val_loss: 0.6040 - val_mean_absolute_error: 0.4505\n",
      "Epoch 460/500\n",
      "360/360 [==============================] - 0s 439us/step - loss: 0.2459 - mean_absolute_error: 0.2143 - val_loss: 0.5817 - val_mean_absolute_error: 0.4436\n",
      "Epoch 461/500\n",
      "360/360 [==============================] - 0s 506us/step - loss: 0.2132 - mean_absolute_error: 0.1678 - val_loss: 0.5328 - val_mean_absolute_error: 0.4235\n",
      "Epoch 462/500\n",
      "360/360 [==============================] - 0s 416us/step - loss: 0.1933 - mean_absolute_error: 0.1539 - val_loss: 0.5626 - val_mean_absolute_error: 0.4372\n",
      "Epoch 463/500\n",
      "360/360 [==============================] - 0s 445us/step - loss: 0.2918 - mean_absolute_error: 0.2370 - val_loss: 0.5783 - val_mean_absolute_error: 0.4337\n",
      "Epoch 464/500\n",
      "360/360 [==============================] - 0s 415us/step - loss: 0.2132 - mean_absolute_error: 0.1791 - val_loss: 0.6183 - val_mean_absolute_error: 0.4687\n",
      "Epoch 465/500\n",
      "360/360 [==============================] - 0s 423us/step - loss: 0.1785 - mean_absolute_error: 0.1419 - val_loss: 0.5554 - val_mean_absolute_error: 0.4290\n",
      "Epoch 466/500\n",
      "360/360 [==============================] - 0s 522us/step - loss: 0.1682 - mean_absolute_error: 0.1274 - val_loss: 0.5382 - val_mean_absolute_error: 0.4308\n",
      "Epoch 467/500\n",
      "360/360 [==============================] - 0s 429us/step - loss: 0.1626 - mean_absolute_error: 0.1184 - val_loss: 0.5546 - val_mean_absolute_error: 0.4453\n",
      "Epoch 468/500\n",
      "360/360 [==============================] - 0s 443us/step - loss: 0.1675 - mean_absolute_error: 0.1253 - val_loss: 0.6336 - val_mean_absolute_error: 0.4751\n",
      "Epoch 469/500\n",
      "360/360 [==============================] - 0s 538us/step - loss: 0.1779 - mean_absolute_error: 0.1446 - val_loss: 0.5772 - val_mean_absolute_error: 0.4533\n",
      "Epoch 470/500\n",
      "360/360 [==============================] - 0s 524us/step - loss: 0.1607 - mean_absolute_error: 0.1192 - val_loss: 0.5725 - val_mean_absolute_error: 0.4497\n",
      "Epoch 471/500\n",
      "360/360 [==============================] - 0s 452us/step - loss: 0.1581 - mean_absolute_error: 0.1159 - val_loss: 0.5431 - val_mean_absolute_error: 0.4354\n",
      "Epoch 472/500\n",
      "360/360 [==============================] - 0s 613us/step - loss: 0.1514 - mean_absolute_error: 0.1074 - val_loss: 0.5612 - val_mean_absolute_error: 0.4451\n",
      "Epoch 473/500\n",
      "360/360 [==============================] - 0s 566us/step - loss: 0.1574 - mean_absolute_error: 0.1193 - val_loss: 0.5495 - val_mean_absolute_error: 0.4384\n",
      "Epoch 474/500\n",
      "360/360 [==============================] - 0s 500us/step - loss: 0.1511 - mean_absolute_error: 0.1067 - val_loss: 0.5779 - val_mean_absolute_error: 0.4495\n",
      "Epoch 475/500\n",
      "360/360 [==============================] - 0s 533us/step - loss: 0.1541 - mean_absolute_error: 0.1144 - val_loss: 0.5910 - val_mean_absolute_error: 0.4444\n",
      "Epoch 476/500\n",
      "360/360 [==============================] - 0s 546us/step - loss: 0.1711 - mean_absolute_error: 0.1253 - val_loss: 0.6554 - val_mean_absolute_error: 0.4711\n",
      "Epoch 477/500\n",
      "360/360 [==============================] - 0s 464us/step - loss: 0.1980 - mean_absolute_error: 0.1719 - val_loss: 0.6745 - val_mean_absolute_error: 0.4824\n",
      "Epoch 478/500\n",
      "360/360 [==============================] - 0s 347us/step - loss: 0.2555 - mean_absolute_error: 0.2213 - val_loss: 0.5563 - val_mean_absolute_error: 0.4157\n",
      "Epoch 479/500\n",
      "360/360 [==============================] - 0s 352us/step - loss: 0.4719 - mean_absolute_error: 0.3615 - val_loss: 0.7484 - val_mean_absolute_error: 0.4794\n",
      "Epoch 480/500\n",
      "360/360 [==============================] - 0s 415us/step - loss: 0.6048 - mean_absolute_error: 0.3840 - val_loss: 0.8063 - val_mean_absolute_error: 0.5581\n",
      "Epoch 481/500\n",
      "360/360 [==============================] - 0s 387us/step - loss: 0.4990 - mean_absolute_error: 0.3966 - val_loss: 0.7052 - val_mean_absolute_error: 0.5041\n",
      "Epoch 482/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360/360 [==============================] - 0s 374us/step - loss: 0.7767 - mean_absolute_error: 0.4719 - val_loss: 0.6615 - val_mean_absolute_error: 0.4905\n",
      "Epoch 483/500\n",
      "360/360 [==============================] - 0s 371us/step - loss: 0.6531 - mean_absolute_error: 0.3982 - val_loss: 0.6836 - val_mean_absolute_error: 0.4635\n",
      "Epoch 484/500\n",
      "360/360 [==============================] - 0s 361us/step - loss: 0.5861 - mean_absolute_error: 0.3460 - val_loss: 0.6384 - val_mean_absolute_error: 0.4939\n",
      "Epoch 485/500\n",
      "360/360 [==============================] - 0s 367us/step - loss: 0.5834 - mean_absolute_error: 0.4144 - val_loss: 0.7701 - val_mean_absolute_error: 0.5174\n",
      "Epoch 486/500\n",
      "360/360 [==============================] - 0s 346us/step - loss: 0.2477 - mean_absolute_error: 0.2239 - val_loss: 0.7092 - val_mean_absolute_error: 0.4850\n",
      "Epoch 487/500\n",
      "360/360 [==============================] - 0s 352us/step - loss: 0.2013 - mean_absolute_error: 0.1606 - val_loss: 0.6590 - val_mean_absolute_error: 0.4605\n",
      "Epoch 488/500\n",
      "360/360 [==============================] - 0s 349us/step - loss: 0.1884 - mean_absolute_error: 0.1679 - val_loss: 0.4875 - val_mean_absolute_error: 0.4212\n",
      "Epoch 489/500\n",
      "360/360 [==============================] - 0s 343us/step - loss: 0.1774 - mean_absolute_error: 0.1511 - val_loss: 0.6215 - val_mean_absolute_error: 0.4626\n",
      "Epoch 490/500\n",
      "360/360 [==============================] - 0s 345us/step - loss: 0.1544 - mean_absolute_error: 0.1126 - val_loss: 0.5324 - val_mean_absolute_error: 0.4292\n",
      "Epoch 491/500\n",
      "360/360 [==============================] - 0s 339us/step - loss: 0.1522 - mean_absolute_error: 0.1120 - val_loss: 0.5707 - val_mean_absolute_error: 0.4396\n",
      "Epoch 492/500\n",
      "360/360 [==============================] - 0s 330us/step - loss: 0.1474 - mean_absolute_error: 0.1046 - val_loss: 0.5781 - val_mean_absolute_error: 0.4433\n",
      "Epoch 493/500\n",
      "360/360 [==============================] - 0s 364us/step - loss: 0.1461 - mean_absolute_error: 0.1085 - val_loss: 0.6180 - val_mean_absolute_error: 0.4583\n",
      "Epoch 494/500\n",
      "360/360 [==============================] - 0s 361us/step - loss: 0.1494 - mean_absolute_error: 0.1123 - val_loss: 0.6324 - val_mean_absolute_error: 0.4714\n",
      "Epoch 495/500\n",
      "360/360 [==============================] - 0s 365us/step - loss: 0.1428 - mean_absolute_error: 0.0994 - val_loss: 0.5681 - val_mean_absolute_error: 0.4508\n",
      "Epoch 496/500\n",
      "360/360 [==============================] - 0s 363us/step - loss: 0.1415 - mean_absolute_error: 0.1000 - val_loss: 0.6227 - val_mean_absolute_error: 0.4643\n",
      "Epoch 497/500\n",
      "360/360 [==============================] - 0s 336us/step - loss: 0.1713 - mean_absolute_error: 0.1507 - val_loss: 0.6467 - val_mean_absolute_error: 0.4797\n",
      "Epoch 498/500\n",
      "360/360 [==============================] - 0s 349us/step - loss: 0.2326 - mean_absolute_error: 0.1953 - val_loss: 0.5606 - val_mean_absolute_error: 0.4492\n",
      "Epoch 499/500\n",
      "360/360 [==============================] - 0s 330us/step - loss: 0.2965 - mean_absolute_error: 0.2313 - val_loss: 1.4356 - val_mean_absolute_error: 0.6832\n",
      "Epoch 500/500\n",
      "360/360 [==============================] - 0s 351us/step - loss: 0.3341 - mean_absolute_error: 0.2664 - val_loss: 0.6042 - val_mean_absolute_error: 0.4587\n"
     ]
    }
   ],
   "source": [
    "# Display training progress by printing a single dot for each completed epoch\n",
    "EPOCHS = 500\n",
    "\n",
    "# Store training stats\n",
    "history = model.fit(train_x, train_y, epochs=EPOCHS,\n",
    "                    \n",
    "                    validation_split=0.1, verbose=1,\n",
    "                    \n",
    "                    batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1ec03550>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_history(history):\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Abs Error [1000$]')\n",
    "    plt.plot(history.epoch, np.array(history.history['mean_absolute_error']),\n",
    "           label='Train Loss')\n",
    "    plt.plot(history.epoch, np.array(history.history['val_mean_absolute_error']),\n",
    "           label = 'Val loss')\n",
    "    plt.legend()\n",
    "    plt.ylim([0, 5])\n",
    "  \n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing set Mean Abs Error: $ 194.20\n"
     ]
    }
   ],
   "source": [
    "[loss, mae] = model.evaluate(train_x, train_y, verbose=0)\n",
    "\n",
    "print(\"Testing set Mean Abs Error: ${:7.2f}\".format(mae * 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = pd.DataFrame(test_predictions)\n",
    "\n",
    "a = list(range(100))\n",
    "ID = pd.DataFrame(a)\n",
    "\n",
    "pre = pd.concat([ID, y_predict], axis = 1)\n",
    "\n",
    "pre.columns = ['Id','time']\n",
    "\n",
    "pre.to_csv('5001_kaggle_prediction.csv',index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22449786901474"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.895666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.543901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.256701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.932554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.691309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.309775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.589355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.362030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.609193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.256701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8.592779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13.142190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.544579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20.333815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.256701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.716883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.446901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.626949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.797390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.275743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.256701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.256701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.328338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.730116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.324254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.033503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.876732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.856255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.595138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2.593829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>11.161020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2.230932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.256701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3.442153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>6.117660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.256701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2.434403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.684793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.623678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.217505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "0    0.895666\n",
       "1    8.543901\n",
       "2    0.256701\n",
       "3    0.932554\n",
       "4    1.691309\n",
       "5    6.309775\n",
       "6    2.589355\n",
       "7    0.362030\n",
       "8   10.609193\n",
       "9    0.256701\n",
       "10   8.592779\n",
       "11  13.142190\n",
       "12   0.544579\n",
       "13  20.333815\n",
       "14   0.256701\n",
       "15   0.716883\n",
       "16   0.446901\n",
       "17   5.626949\n",
       "18   2.797390\n",
       "19   2.275743\n",
       "20   0.256701\n",
       "21   0.256701\n",
       "22   0.328338\n",
       "23   0.730116\n",
       "24   1.324254\n",
       "25   1.033503\n",
       "26   1.876732\n",
       "27   1.856255\n",
       "28   1.595138\n",
       "29   2.593829\n",
       "30  11.161020\n",
       "31   2.230932\n",
       "32   0.256701\n",
       "33   3.442153\n",
       "34   6.117660\n",
       "35   0.256701\n",
       "36   2.434403\n",
       "37   1.684793\n",
       "38   0.623678\n",
       "39   1.217505"
      ]
     },
     "execution_count": 1116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict[0:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1074,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>flip_y</th>\n",
       "      <th>l1_ratio</th>\n",
       "      <th>max_iter</th>\n",
       "      <th>n_classes</th>\n",
       "      <th>n_clusters_per_class</th>\n",
       "      <th>n_features</th>\n",
       "      <th>n_informative</th>\n",
       "      <th>n_jobs</th>\n",
       "      <th>n_samples</th>\n",
       "      <th>penalty</th>\n",
       "      <th>scale</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.074798</td>\n",
       "      <td>0.304083</td>\n",
       "      <td>417</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>327</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>1089</td>\n",
       "      <td>0</td>\n",
       "      <td>24.242009</td>\n",
       "      <td>0.409987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.077781</td>\n",
       "      <td>0.727744</td>\n",
       "      <td>578</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>373</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>790</td>\n",
       "      <td>2</td>\n",
       "      <td>54.626302</td>\n",
       "      <td>3.950953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.030196</td>\n",
       "      <td>0.745885</td>\n",
       "      <td>588</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1198</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>428</td>\n",
       "      <td>0</td>\n",
       "      <td>17.999964</td>\n",
       "      <td>0.368702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.057261</td>\n",
       "      <td>0.474605</td>\n",
       "      <td>829</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>313</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>877</td>\n",
       "      <td>0</td>\n",
       "      <td>82.257222</td>\n",
       "      <td>1.004559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.073728</td>\n",
       "      <td>0.395049</td>\n",
       "      <td>167</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>644</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>216</td>\n",
       "      <td>3</td>\n",
       "      <td>95.515601</td>\n",
       "      <td>0.802800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0.097483</td>\n",
       "      <td>0.358837</td>\n",
       "      <td>986</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>861</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1396</td>\n",
       "      <td>2</td>\n",
       "      <td>31.973447</td>\n",
       "      <td>7.916113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.095324</td>\n",
       "      <td>0.758565</td>\n",
       "      <td>929</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>691</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>908</td>\n",
       "      <td>0</td>\n",
       "      <td>98.238367</td>\n",
       "      <td>2.206062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.040463</td>\n",
       "      <td>0.282841</td>\n",
       "      <td>422</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>737</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>677</td>\n",
       "      <td>2</td>\n",
       "      <td>54.628206</td>\n",
       "      <td>2.407143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>0.025639</td>\n",
       "      <td>0.766176</td>\n",
       "      <td>308</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1191</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>498</td>\n",
       "      <td>2</td>\n",
       "      <td>54.166346</td>\n",
       "      <td>1.002341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0.024620</td>\n",
       "      <td>0.249018</td>\n",
       "      <td>510</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>803</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>1380</td>\n",
       "      <td>1</td>\n",
       "      <td>75.048054</td>\n",
       "      <td>1.607144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0.017705</td>\n",
       "      <td>0.868100</td>\n",
       "      <td>479</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1047</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1178</td>\n",
       "      <td>0</td>\n",
       "      <td>73.658816</td>\n",
       "      <td>0.905699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0.036165</td>\n",
       "      <td>0.574206</td>\n",
       "      <td>259</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>639</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>860</td>\n",
       "      <td>1</td>\n",
       "      <td>82.904841</td>\n",
       "      <td>1.003842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0.077584</td>\n",
       "      <td>0.421956</td>\n",
       "      <td>618</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>195</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>628</td>\n",
       "      <td>3</td>\n",
       "      <td>12.870010</td>\n",
       "      <td>0.803387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>0.085757</td>\n",
       "      <td>0.498461</td>\n",
       "      <td>668</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>1370</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>47.619377</td>\n",
       "      <td>1.207392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0.087699</td>\n",
       "      <td>0.658724</td>\n",
       "      <td>386</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1090</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>907</td>\n",
       "      <td>1</td>\n",
       "      <td>43.704770</td>\n",
       "      <td>1.507312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0.005869</td>\n",
       "      <td>0.193892</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>573</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>23.338030</td>\n",
       "      <td>0.101734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>0.087911</td>\n",
       "      <td>0.796023</td>\n",
       "      <td>691</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1276</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>484</td>\n",
       "      <td>0</td>\n",
       "      <td>86.080493</td>\n",
       "      <td>1.564080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>0.054385</td>\n",
       "      <td>0.631750</td>\n",
       "      <td>719</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>209</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>76.888075</td>\n",
       "      <td>0.603312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>0.025358</td>\n",
       "      <td>0.431559</td>\n",
       "      <td>265</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1001</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>646</td>\n",
       "      <td>3</td>\n",
       "      <td>53.095291</td>\n",
       "      <td>1.405601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0.043639</td>\n",
       "      <td>0.734566</td>\n",
       "      <td>365</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>877</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1251</td>\n",
       "      <td>3</td>\n",
       "      <td>89.984670</td>\n",
       "      <td>6.013842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.728533</td>\n",
       "      <td>213</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>128</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>222</td>\n",
       "      <td>0</td>\n",
       "      <td>20.919171</td>\n",
       "      <td>0.104154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>0.066472</td>\n",
       "      <td>0.660039</td>\n",
       "      <td>280</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>646</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>336</td>\n",
       "      <td>3</td>\n",
       "      <td>17.711963</td>\n",
       "      <td>0.504131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0.031039</td>\n",
       "      <td>0.677498</td>\n",
       "      <td>213</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>562</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>859</td>\n",
       "      <td>0</td>\n",
       "      <td>43.451403</td>\n",
       "      <td>0.603173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>0.025607</td>\n",
       "      <td>0.184390</td>\n",
       "      <td>306</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>611</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>704</td>\n",
       "      <td>0</td>\n",
       "      <td>26.313838</td>\n",
       "      <td>0.308614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0.084397</td>\n",
       "      <td>0.501122</td>\n",
       "      <td>695</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>405</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>893</td>\n",
       "      <td>2</td>\n",
       "      <td>90.247000</td>\n",
       "      <td>3.107064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>0.047897</td>\n",
       "      <td>0.627662</td>\n",
       "      <td>871</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>468</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "      <td>52.697092</td>\n",
       "      <td>0.542533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>0.042227</td>\n",
       "      <td>0.324578</td>\n",
       "      <td>973</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>245</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>426</td>\n",
       "      <td>3</td>\n",
       "      <td>81.578235</td>\n",
       "      <td>3.107124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0.088964</td>\n",
       "      <td>0.856195</td>\n",
       "      <td>763</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>130</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>584</td>\n",
       "      <td>1</td>\n",
       "      <td>39.541429</td>\n",
       "      <td>0.302663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>0.042828</td>\n",
       "      <td>0.247043</td>\n",
       "      <td>130</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>960</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1244</td>\n",
       "      <td>0</td>\n",
       "      <td>19.313554</td>\n",
       "      <td>0.307453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>0.028191</td>\n",
       "      <td>0.634388</td>\n",
       "      <td>846</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1243</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>409</td>\n",
       "      <td>0</td>\n",
       "      <td>56.159863</td>\n",
       "      <td>2.706453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>1</td>\n",
       "      <td>0.029431</td>\n",
       "      <td>0.660444</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1535</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>1111</td>\n",
       "      <td>0</td>\n",
       "      <td>53.872351</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>0</td>\n",
       "      <td>0.081759</td>\n",
       "      <td>0.740822</td>\n",
       "      <td>359</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>902</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1021</td>\n",
       "      <td>1</td>\n",
       "      <td>79.581585</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>0</td>\n",
       "      <td>0.058142</td>\n",
       "      <td>0.297281</td>\n",
       "      <td>566</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>901</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1609</td>\n",
       "      <td>2</td>\n",
       "      <td>78.508748</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>1</td>\n",
       "      <td>0.043647</td>\n",
       "      <td>0.193580</td>\n",
       "      <td>554</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>516</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>711</td>\n",
       "      <td>1</td>\n",
       "      <td>58.310818</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>1</td>\n",
       "      <td>0.052746</td>\n",
       "      <td>0.367283</td>\n",
       "      <td>182</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1526</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1930</td>\n",
       "      <td>2</td>\n",
       "      <td>80.035845</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>1</td>\n",
       "      <td>0.079694</td>\n",
       "      <td>0.171262</td>\n",
       "      <td>981</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1382</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1069</td>\n",
       "      <td>1</td>\n",
       "      <td>89.075015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>2</td>\n",
       "      <td>0.069970</td>\n",
       "      <td>0.209963</td>\n",
       "      <td>768</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1501</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>820</td>\n",
       "      <td>0</td>\n",
       "      <td>21.095990</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>0</td>\n",
       "      <td>0.011654</td>\n",
       "      <td>0.677357</td>\n",
       "      <td>775</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1446</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>772</td>\n",
       "      <td>1</td>\n",
       "      <td>37.428210</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>0</td>\n",
       "      <td>0.092600</td>\n",
       "      <td>0.342990</td>\n",
       "      <td>207</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1737</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>502</td>\n",
       "      <td>3</td>\n",
       "      <td>66.129315</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>0</td>\n",
       "      <td>0.046557</td>\n",
       "      <td>0.372089</td>\n",
       "      <td>171</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1004</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1538</td>\n",
       "      <td>1</td>\n",
       "      <td>55.910058</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>1</td>\n",
       "      <td>0.038335</td>\n",
       "      <td>0.665248</td>\n",
       "      <td>485</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1242</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1688</td>\n",
       "      <td>3</td>\n",
       "      <td>4.584513</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>0</td>\n",
       "      <td>0.058821</td>\n",
       "      <td>0.109234</td>\n",
       "      <td>721</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1617</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1609</td>\n",
       "      <td>0</td>\n",
       "      <td>22.895050</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>1</td>\n",
       "      <td>0.038373</td>\n",
       "      <td>0.736432</td>\n",
       "      <td>802</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1442</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1767</td>\n",
       "      <td>1</td>\n",
       "      <td>8.536702</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>2</td>\n",
       "      <td>0.055262</td>\n",
       "      <td>0.605113</td>\n",
       "      <td>297</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>758</td>\n",
       "      <td>2</td>\n",
       "      <td>22.863985</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>2</td>\n",
       "      <td>0.054528</td>\n",
       "      <td>0.126654</td>\n",
       "      <td>478</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>377</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>253</td>\n",
       "      <td>2</td>\n",
       "      <td>88.170202</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>0</td>\n",
       "      <td>0.031862</td>\n",
       "      <td>0.838096</td>\n",
       "      <td>461</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1387</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1984</td>\n",
       "      <td>0</td>\n",
       "      <td>81.318071</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>0</td>\n",
       "      <td>0.076431</td>\n",
       "      <td>0.465490</td>\n",
       "      <td>377</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1858</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>1210</td>\n",
       "      <td>2</td>\n",
       "      <td>81.731202</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>1</td>\n",
       "      <td>0.048385</td>\n",
       "      <td>0.658324</td>\n",
       "      <td>952</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1013</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>163</td>\n",
       "      <td>0</td>\n",
       "      <td>65.404799</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>2</td>\n",
       "      <td>0.047257</td>\n",
       "      <td>0.141647</td>\n",
       "      <td>537</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>311</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1234</td>\n",
       "      <td>3</td>\n",
       "      <td>34.149713</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>2</td>\n",
       "      <td>0.099070</td>\n",
       "      <td>0.197850</td>\n",
       "      <td>289</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>478</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>991</td>\n",
       "      <td>0</td>\n",
       "      <td>70.799117</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>0</td>\n",
       "      <td>0.098612</td>\n",
       "      <td>0.750411</td>\n",
       "      <td>414</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>872</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>527</td>\n",
       "      <td>3</td>\n",
       "      <td>75.513593</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>0</td>\n",
       "      <td>0.013769</td>\n",
       "      <td>0.394079</td>\n",
       "      <td>249</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>349</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1297</td>\n",
       "      <td>1</td>\n",
       "      <td>62.582421</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>2</td>\n",
       "      <td>0.087429</td>\n",
       "      <td>0.562093</td>\n",
       "      <td>818</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1180</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>1096</td>\n",
       "      <td>0</td>\n",
       "      <td>87.441176</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>0</td>\n",
       "      <td>0.010380</td>\n",
       "      <td>0.177963</td>\n",
       "      <td>927</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1267</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1203</td>\n",
       "      <td>2</td>\n",
       "      <td>72.668364</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>0</td>\n",
       "      <td>0.094834</td>\n",
       "      <td>0.425325</td>\n",
       "      <td>607</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1474</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>850</td>\n",
       "      <td>1</td>\n",
       "      <td>71.244262</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>0.443809</td>\n",
       "      <td>567</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1028</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1650</td>\n",
       "      <td>0</td>\n",
       "      <td>27.597471</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>1</td>\n",
       "      <td>0.009611</td>\n",
       "      <td>0.441950</td>\n",
       "      <td>613</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>946</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1493</td>\n",
       "      <td>2</td>\n",
       "      <td>64.480380</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0</td>\n",
       "      <td>0.044531</td>\n",
       "      <td>0.687174</td>\n",
       "      <td>298</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1177</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>408</td>\n",
       "      <td>1</td>\n",
       "      <td>50.289568</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0</td>\n",
       "      <td>0.003045</td>\n",
       "      <td>0.631403</td>\n",
       "      <td>800</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1035</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>227</td>\n",
       "      <td>0</td>\n",
       "      <td>68.057286</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>2</td>\n",
       "      <td>0.099525</td>\n",
       "      <td>0.641818</td>\n",
       "      <td>269</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>739</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>116</td>\n",
       "      <td>1</td>\n",
       "      <td>36.027457</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows  13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     alpha    flip_y  l1_ratio  max_iter  n_classes  n_clusters_per_class  \\\n",
       "0        0  0.074798  0.304083       417          4                     3   \n",
       "1        1  0.077781  0.727744       578          4                     5   \n",
       "2        2  0.030196  0.745885       588          2                     5   \n",
       "3        1  0.057261  0.474605       829          6                     5   \n",
       "4        1  0.073728  0.395049       167          8                     5   \n",
       "5        1  0.097483  0.358837       986          4                     2   \n",
       "6        0  0.095324  0.758565       929          5                     2   \n",
       "7        0  0.040463  0.282841       422          9                     5   \n",
       "8        2  0.025639  0.766176       308          2                     4   \n",
       "9        1  0.024620  0.249018       510          9                     5   \n",
       "10       0  0.017705  0.868100       479          7                     4   \n",
       "11       0  0.036165  0.574206       259         10                     2   \n",
       "12       1  0.077584  0.421956       618          3                     5   \n",
       "13       2  0.085757  0.498461       668          9                     4   \n",
       "14       0  0.087699  0.658724       386          5                     3   \n",
       "15       0  0.005869  0.193892       103          3                     3   \n",
       "16       2  0.087911  0.796023       691          3                     5   \n",
       "17       2  0.054385  0.631750       719          9                     3   \n",
       "18       1  0.025358  0.431559       265          3                     5   \n",
       "19       0  0.043639  0.734566       365          4                     4   \n",
       "20       1  0.000842  0.728533       213          6                     4   \n",
       "21       1  0.066472  0.660039       280          3                     5   \n",
       "22       0  0.031039  0.677498       213          8                     2   \n",
       "23       2  0.025607  0.184390       306         10                     5   \n",
       "24       0  0.084397  0.501122       695          3                     2   \n",
       "25       1  0.047897  0.627662       871          6                     3   \n",
       "26       1  0.042227  0.324578       973          7                     3   \n",
       "27       0  0.088964  0.856195       763          6                     4   \n",
       "28       1  0.042828  0.247043       130         10                     2   \n",
       "29       2  0.028191  0.634388       846          9                     5   \n",
       "..     ...       ...       ...       ...        ...                   ...   \n",
       "470      1  0.029431  0.660444       104          3                     3   \n",
       "471      0  0.081759  0.740822       359          3                     5   \n",
       "472      0  0.058142  0.297281       566          4                     2   \n",
       "473      1  0.043647  0.193580       554          2                     5   \n",
       "474      1  0.052746  0.367283       182          6                     3   \n",
       "475      1  0.079694  0.171262       981          3                     3   \n",
       "476      2  0.069970  0.209963       768          5                     4   \n",
       "477      0  0.011654  0.677357       775          7                     3   \n",
       "478      0  0.092600  0.342990       207          9                     3   \n",
       "479      0  0.046557  0.372089       171          4                     3   \n",
       "480      1  0.038335  0.665248       485          8                     4   \n",
       "481      0  0.058821  0.109234       721          6                     4   \n",
       "482      1  0.038373  0.736432       802          7                     4   \n",
       "483      2  0.055262  0.605113       297          6                     3   \n",
       "484      2  0.054528  0.126654       478          8                     4   \n",
       "485      0  0.031862  0.838096       461          7                     2   \n",
       "486      0  0.076431  0.465490       377          5                     4   \n",
       "487      1  0.048385  0.658324       952          8                     5   \n",
       "488      2  0.047257  0.141647       537          7                     2   \n",
       "489      2  0.099070  0.197850       289         10                     2   \n",
       "490      0  0.098612  0.750411       414          8                     4   \n",
       "491      0  0.013769  0.394079       249          6                     2   \n",
       "492      2  0.087429  0.562093       818          4                     5   \n",
       "493      0  0.010380  0.177963       927          5                     3   \n",
       "494      0  0.094834  0.425325       607          8                     4   \n",
       "495      0  0.035500  0.443809       567          5                     5   \n",
       "496      1  0.009611  0.441950       613         10                     4   \n",
       "497      0  0.044531  0.687174       298          5                     3   \n",
       "498      0  0.003045  0.631403       800         10                     3   \n",
       "499      2  0.099525  0.641818       269          4                     5   \n",
       "\n",
       "     n_features  n_informative  n_jobs  n_samples  penalty      scale  \\\n",
       "0           327              7       8       1089        0  24.242009   \n",
       "1           373              7       1        790        2  54.626302   \n",
       "2          1198              6       2        428        0  17.999964   \n",
       "3           313              7       4        877        0  82.257222   \n",
       "4           644             11       2        216        3  95.515601   \n",
       "5           861              6       4       1396        2  31.973447   \n",
       "6           691              6       2        908        0  98.238367   \n",
       "7           737              8       8        677        2  54.628206   \n",
       "8          1191              9       8        498        2  54.166346   \n",
       "9           803             10       8       1380        1  75.048054   \n",
       "10         1047              8       8       1178        0  73.658816   \n",
       "11          639             11       2        860        1  82.904841   \n",
       "12          195              9       4        628        3  12.870010   \n",
       "13         1370              8       8        500        1  47.619377   \n",
       "14         1090              9       2        907        1  43.704770   \n",
       "15          573              8       2        111        0  23.338030   \n",
       "16         1276              7       1        484        0  86.080493   \n",
       "17          209              9       2        103        3  76.888075   \n",
       "18         1001              7       4        646        3  53.095291   \n",
       "19          877             11       2       1251        3  89.984670   \n",
       "20          128              8       4        222        0  20.919171   \n",
       "21          646              6       8        336        3  17.711963   \n",
       "22          562              9       2        859        0  43.451403   \n",
       "23          611              8       8        704        0  26.313838   \n",
       "24          405              6       2        893        2  90.247000   \n",
       "25          468              9       1        173        0  52.697092   \n",
       "26          245              9       2        426        3  81.578235   \n",
       "27          130             11       4        584        1  39.541429   \n",
       "28          960              9       8       1244        0  19.313554   \n",
       "29         1243             11       2        409        0  56.159863   \n",
       "..          ...            ...     ...        ...      ...        ...   \n",
       "470        1535              9      16       1111        0  53.872351   \n",
       "471         902             10       2       1021        1  79.581585   \n",
       "472         901              9       2       1609        2  78.508748   \n",
       "473         516              7       4        711        1  58.310818   \n",
       "474        1526              7       4       1930        2  80.035845   \n",
       "475        1382             10       1       1069        1  89.075015   \n",
       "476        1501             11       8        820        0  21.095990   \n",
       "477        1446             10       2        772        1  37.428210   \n",
       "478        1737             11       4        502        3  66.129315   \n",
       "479        1004              7       1       1538        1  55.910058   \n",
       "480        1242              8       8       1688        3   4.584513   \n",
       "481        1617              7       4       1609        0  22.895050   \n",
       "482        1442             11       4       1767        1   8.536702   \n",
       "483         500              7       8        758        2  22.863985   \n",
       "484         377             12       2        253        2  88.170202   \n",
       "485        1387              7       4       1984        0  81.318071   \n",
       "486        1858              7       8       1210        2  81.731202   \n",
       "487        1013             11       8        163        0  65.404799   \n",
       "488         311              7       2       1234        3  34.149713   \n",
       "489         478              8       2        991        0  70.799117   \n",
       "490         872              8       4        527        3  75.513593   \n",
       "491         349              8       1       1297        1  62.582421   \n",
       "492        1180             11       8       1096        0  87.441176   \n",
       "493        1267              6       4       1203        2  72.668364   \n",
       "494        1474             10       1        850        1  71.244262   \n",
       "495        1028              8       2       1650        0  27.597471   \n",
       "496         946             12       1       1493        2  64.480380   \n",
       "497        1177              6       8        408        1  50.289568   \n",
       "498        1035              8       4        227        0  68.057286   \n",
       "499         739             10       1        116        1  36.027457   \n",
       "\n",
       "         time  \n",
       "0    0.409987  \n",
       "1    3.950953  \n",
       "2    0.368702  \n",
       "3    1.004559  \n",
       "4    0.802800  \n",
       "5    7.916113  \n",
       "6    2.206062  \n",
       "7    2.407143  \n",
       "8    1.002341  \n",
       "9    1.607144  \n",
       "10   0.905699  \n",
       "11   1.003842  \n",
       "12   0.803387  \n",
       "13   1.207392  \n",
       "14   1.507312  \n",
       "15   0.101734  \n",
       "16   1.564080  \n",
       "17   0.603312  \n",
       "18   1.405601  \n",
       "19   6.013842  \n",
       "20   0.104154  \n",
       "21   0.504131  \n",
       "22   0.603173  \n",
       "23   0.308614  \n",
       "24   3.107064  \n",
       "25   0.542533  \n",
       "26   3.107124  \n",
       "27   0.302663  \n",
       "28   0.307453  \n",
       "29   2.706453  \n",
       "..        ...  \n",
       "470       NaN  \n",
       "471       NaN  \n",
       "472       NaN  \n",
       "473       NaN  \n",
       "474       NaN  \n",
       "475       NaN  \n",
       "476       NaN  \n",
       "477       NaN  \n",
       "478       NaN  \n",
       "479       NaN  \n",
       "480       NaN  \n",
       "481       NaN  \n",
       "482       NaN  \n",
       "483       NaN  \n",
       "484       NaN  \n",
       "485       NaN  \n",
       "486       NaN  \n",
       "487       NaN  \n",
       "488       NaN  \n",
       "489       NaN  \n",
       "490       NaN  \n",
       "491       NaN  \n",
       "492       NaN  \n",
       "493       NaN  \n",
       "494       NaN  \n",
       "495       NaN  \n",
       "496       NaN  \n",
       "497       NaN  \n",
       "498       NaN  \n",
       "499       NaN  \n",
       "\n",
       "[500 rows x 13 columns]"
      ]
     },
     "execution_count": 1074,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
